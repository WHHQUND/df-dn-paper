{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox import *\n",
    "import warnings\n",
    "import argparse\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import librosa\n",
    "import time\n",
    "import re\n",
    "from timeout_decorator import timeout\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ConfigSpace import (\n",
    "    Categorical,\n",
    "    Configuration,\n",
    "    ConfigurationSpace,\n",
    "    EqualsCondition,\n",
    "    Float,\n",
    "    InCondition,\n",
    "    Integer,\n",
    ")\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "import itertools\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skopt.callbacks import DeadlineStopper\n",
    "\n",
    "from smac import MultiFidelityFacade as MFFacade\n",
    "from smac import Scenario\n",
    "from smac.facade import AbstractFacade\n",
    "from smac.intensifier.hyperband import Hyperband\n",
    "from smac.intensifier.successive_halving import SuccessiveHalving\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import torchaudio.transforms as trans\n",
    "import re\n",
    "\n",
    "from line_profiler import LineProfiler\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_combination = [20, 100, 180, 260, 340, 400]\n",
    "dataset_indices_max = 16\n",
    "max_shape_to_run = 10000\n",
    "alpha_range_nn = [0.001, 0.01, 0.1]\n",
    "subsample = [0.5, 0.8, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][_api_calls.py:103] Starting [get] request for the URL https://www.openml.org/api/v1/xml/study/337\n",
      "[INFO][_api_calls.py:115] 5.4754562s taken for [get] request for the URL https://www.openml.org/api/v1/xml/study/337\n",
      "[INFO][dataset.py:555] pickle write credit\n",
      "[INFO][dataset.py:555] pickle write electricity\n",
      "[INFO][dataset.py:555] pickle write covertype\n",
      "[INFO][dataset.py:555] pickle write pol\n",
      "[INFO][dataset.py:555] pickle write house_16H\n",
      "[INFO][dataset.py:555] pickle write MagicTelescope\n",
      "[INFO][dataset.py:555] pickle write bank-marketing\n",
      "[INFO][dataset.py:555] pickle write MiniBooNE\n",
      "[INFO][dataset.py:555] pickle write Higgs\n",
      "[INFO][dataset.py:555] pickle write eye_movements\n",
      "[INFO][dataset.py:555] pickle write Diabetes130US\n",
      "[INFO][dataset.py:555] pickle write jannis\n",
      "[INFO][dataset.py:555] pickle write default-of-credit-card-clients\n",
      "[INFO][dataset.py:555] pickle write Bioresponse\n",
      "[INFO][dataset.py:555] pickle write california\n",
      "[INFO][dataset.py:555] pickle write heloc\n",
      "\n",
      "\n",
      "Current Dataset:  0\n",
      "No string columns to encode\n",
      "X scalered\n",
      "\n",
      "\n",
      "Current Dataset:  1\n",
      "No string columns to encode\n",
      "X scalered\n",
      "\n",
      "\n",
      "Current Dataset:  2\n",
      "No string columns to encode\n",
      "X scalered\n",
      "\n",
      "\n",
      "Current Dataset:  3\n",
      "No string columns to encode\n",
      "X scalered\n",
      "\n",
      "\n",
      "Current Dataset:  4\n",
      "No string columns to encode\n",
      "X scalered\n",
      "\n",
      "\n",
      "Current Dataset:  5\n",
      "No string columns to encode\n",
      "X scalered\n",
      "\n",
      "\n",
      "Current Dataset:  6\n",
      "No string columns to encode\n",
      "X scalered\n",
      "\n",
      "\n",
      "Current Dataset:  7\n",
      "No string columns to encode\n",
      "X scalered\n",
      "\n",
      "\n",
      "Current Dataset:  8\n",
      "No string columns to encode\n",
      "X scalered\n",
      "\n",
      "\n",
      "Current Dataset:  9\n",
      "No string columns to encode\n",
      "X scalered\n",
      "\n",
      "\n",
      "Current Dataset:  10\n",
      "No string columns to encode\n",
      "X scalered\n",
      "\n",
      "\n",
      "Current Dataset:  11\n",
      "No string columns to encode\n",
      "X scalered\n",
      "\n",
      "\n",
      "Current Dataset:  12\n",
      "No string columns to encode\n",
      "X scalered\n",
      "\n",
      "\n",
      "Current Dataset:  13\n",
      "No string columns to encode\n",
      "X scalered\n",
      "\n",
      "\n",
      "Current Dataset:  14\n",
      "No string columns to encode\n",
      "X scalered\n",
      "\n",
      "\n",
      "Current Dataset:  15\n",
      "No string columns to encode\n",
      "X scalered\n"
     ]
    }
   ],
   "source": [
    "dataset_indices = list(range(dataset_indices_max))\n",
    "dict_data_indices = {dataset_ind: {} for dataset_ind in dataset_indices}\n",
    "encode_cnt = 0\n",
    "\n",
    "X_data_list = []\n",
    "y_data_list = []\n",
    "dataset_names = []\n",
    "def import_datasets():\n",
    "    SUITE_ID = [337]\n",
    "    for i in SUITE_ID:\n",
    "        benchmark_suite = openml.study.get_suite(i)\n",
    "        for task_id in benchmark_suite.tasks:  # iterate over all tasks\n",
    "            task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "            dataset = task.get_dataset()\n",
    "            X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "                dataset_format=\"dataframe\", target=dataset.default_target_attribute\n",
    "            )   \n",
    "\n",
    "            # ### Covert labels to numerical values\n",
    "            # le = LabelEncoder()\n",
    "            # y_encoded = le.fit_transform(y)\n",
    "            # y = pd.DataFrame(y_encoded)\n",
    "\n",
    "            X_data_list.append(X)\n",
    "            y_data_list.append(y)\n",
    "            dataset_names.append(dataset.name)\n",
    "\n",
    "            # print(\" \")\n",
    "            # print(\" SUITE_ID:\", i)\n",
    "            # print(\"X_data_list length:\", len(X_data_list))\n",
    "            # print(\" \")\n",
    "    \n",
    "import_datasets()\n",
    "\n",
    "train_x_list = X_data_list.copy()\n",
    "train_y_list = y_data_list.copy()\n",
    "val_x_list = X_data_list.copy()\n",
    "val_y_list = y_data_list.copy()\n",
    "\n",
    "for dataset_index, dataset in enumerate(dataset_indices):\n",
    "    print(\"\\n\\nCurrent Dataset: \", dataset)\n",
    "\n",
    "    X = X_data_list[dataset]\n",
    "    y = y_data_list[dataset]\n",
    "\n",
    "    if X.shape[0] > max_shape_to_run:\n",
    "        X, y = sample_large_datasets(X, y)\n",
    "    \n",
    "    np.random.seed(dataset_index)\n",
    "    dict_data_indices = find_indices_train_val_test(\n",
    "        X.shape[0], dict_data_indices=dict_data_indices, dataset_ind=dataset_index\n",
    "    )\n",
    "    train_indices = dict_data_indices[dataset_index][\"train\"]\n",
    "    val_indices = dict_data_indices[dataset_index][\"val\"]\n",
    "\n",
    "    ### Covert labels to numerical values\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    # y = pd.DataFrame(y_encoded)\n",
    "    y = y_encoded\n",
    "\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X)\n",
    "    # print(X.dtypes)\n",
    "\n",
    "    ### Convert categories features to numerical features\n",
    "    # print(\"X shape: \", X.shape)\n",
    "    categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "    numeric_columns = X.select_dtypes(include=['number']).columns\n",
    "\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    if len(categorical_columns) > 0:\n",
    "        X_encoded_strings = encoder.fit_transform(X[categorical_columns])\n",
    "\n",
    "        X = np.hstack((X[numeric_columns].values, X_encoded_strings))\n",
    "        print(\"Encoded\", len(categorical_columns), \" columns\")\n",
    "        encode_cnt += 1\n",
    "    else:\n",
    "        print(\"No string columns to encode\")\n",
    "    \n",
    "    # print(\"X_encoded shape: \", X.shape)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    # X = pd.DataFrame(X)\n",
    "    train_x_list[dataset] = X[train_indices]\n",
    "    train_y_list[dataset] = y[train_indices]\n",
    "    val_x_list[dataset] = X[val_indices]\n",
    "    val_y_list[dataset] = y[val_indices]\n",
    "    print(\"X scalered\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['credit', 'electricity', 'covertype', 'pol', 'house_16H', 'MagicTelescope', 'bank-marketing', 'MiniBooNE', 'Higgs', 'eye_movements', 'Diabetes130US', 'jannis', 'default-of-credit-card-clients', 'Bioresponse', 'california', 'heloc']\n",
      "16\n",
      "(5000, 10)\n",
      "(5000,)\n",
      "(2500, 10)\n",
      "(2500,)\n"
     ]
    }
   ],
   "source": [
    "train_x = train_x_list[0]\n",
    "train_y = train_y_list[0]\n",
    "val_x = val_x_list[0]\n",
    "val_y = val_y_list[0]\n",
    "num_class = len(np.unique(train_y))\n",
    "# print(np.unique(train_y))\n",
    "# print(type(train_x))\n",
    "# print(type(train_y))\n",
    "print(dataset_names)\n",
    "print(len(dataset_names))\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(val_x.shape)\n",
    "print(val_y.shape)\n",
    "\n",
    "# categorical_columns = train_x.select_dtypes(include=['category']).columns\n",
    "\n",
    "# if not categorical_columns.empty:\n",
    "#     print(\"There are categorical columns:\", categorical_columns)\n",
    "# else:\n",
    "#     print(\"No categorical columns found.\")\n",
    "\n",
    "# print(train_x.head(5))\n",
    "# print(train_x['day'].cat.categories.is_numeric())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_estimators=100, random_state=317)\n",
    "XGBT = xgb.XGBClassifier(n_estimators=100, random_state=317)\n",
    "TabNet = TabNetClassifier(n_d=8, n_a=8, n_steps=5, gamma=1.3, n_independent=2, n_shared=2, seed=317, optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=1e-2), scheduler_params={\"step_size\":50, \"gamma\":0.9}, scheduler_fn=torch.optim.lr_scheduler.StepLR, mask_type='entmax', verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBTWrapper(BaseEstimator):\n",
    "    def __init__(self, n_estimators=100, max_depth=2, seed= 317, min_child_weight=1, gamma=0.1, subsample=0.8, colsample_bytree=0.5, learning_rate=0.1, objective='binary:logistic', colsample_bylevel=0.5, colsample_bynode=0.5):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.seed= seed\n",
    "        self.min_child_weight = min_child_weight\n",
    "        self.gamma = gamma\n",
    "        self.subsample = subsample\n",
    "        self.colsample_bytree = colsample_bytree\n",
    "        self.colsample_bylevel = colsample_bylevel\n",
    "        self.colsample_bynode = colsample_bynode\n",
    "        self.learning_rate = learning_rate\n",
    "        self.objective = objective\n",
    "        # self.num_class = num_class\n",
    "        self.model = xgb.XGBClassifier(n_estimators=self.n_estimators, max_depth=self.max_depth, seed=self.seed, min_child_weight=self.min_child_weight, gamma=self.gamma, subsample=self.subsample, colsample_bytree=self.colsample_bytree, colsample_bylevel=self.colsample_bylevel, colsample_bynode=self.colsample_bynode ,learning_rate=self.learning_rate, objective=self.objective)\n",
    "\n",
    "    @property\n",
    "    def configspace(self) -> ConfigurationSpace:\n",
    "        cs = ConfigurationSpace()\n",
    "        n_estimators = Integer(\"n_estimators\", (100, 1200), default=100)\n",
    "        max_depth = Integer(\"max_depth\", (2, 21), default=2)\n",
    "        min_child_weight = Integer(\"min_child_weight\", (1, 10), default=1)\n",
    "        gamma = Float(\"gamma\", (0.1, 1.0), default=0.1)\n",
    "        subsample = Float(\"subsample\", (0.5, 1.0), default=0.8)\n",
    "        colsample_bytree = Float(\"colsample_bytree\", (0.3, 1.0), default=0.6)\n",
    "        colsample_bylevel = Float(\"colsample_bylevel\", (0.3, 1.0), default=0.6)\n",
    "        colsample_bynode = Float(\"colsample_bynode\", (0.3, 1.0), default=0.6)\n",
    "        learning_rate = Float(\"learning_rate\", (0.001, 0.3), default=0.1)\n",
    "        cs.add_hyperparameters([n_estimators, max_depth, min_child_weight, gamma, subsample, colsample_bytree, colsample_bylevel, colsample_bynode, learning_rate])\n",
    "        return cs\n",
    "    \n",
    "    def fit(self, config: Configuration, seed: int = 0, budget: int = 250) -> float: \n",
    "        config = dict(config)  \n",
    "        self.model.set_params(**config)\n",
    "        X = train_x\n",
    "        y = train_y\n",
    "        # print(\"X shape: \", X.shape)\n",
    "        # print(\"y shape: \", y.shape)\n",
    "        self.model.fit(X, y)\n",
    "        preds = self.model.predict(X)\n",
    "        scores = accuracy_score(y, preds)\n",
    "        \n",
    "        return 1 - scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeout(900)\n",
    "def main():\n",
    "    GBT = XGBTWrapper()\n",
    "\n",
    "    facades: list[AbstractFacade] = []\n",
    "    for intensifier_object in [Hyperband]:\n",
    "\n",
    "        scenario = Scenario(\n",
    "            GBT.configspace,\n",
    "            walltime_limit=600,\n",
    "            output_directory=Path(\"smac_hyperband_output_budget_10mins_XGBT\"),\n",
    "            n_trials=10000,\n",
    "            min_budget=100,\n",
    "            max_budget=1000,\n",
    "            n_workers=8,\n",
    "\n",
    "        )\n",
    "\n",
    "        initial_design = MFFacade.get_initial_design(scenario, n_configs=5)\n",
    "        intensifier = intensifier_object(scenario, incumbent_selection=\"highest_budget\")\n",
    "\n",
    "        smac = MFFacade(\n",
    "            scenario,\n",
    "            GBT.fit,\n",
    "            initial_design=initial_design,\n",
    "            intensifier=intensifier,\n",
    "            overwrite=True,\n",
    "        )\n",
    "\n",
    "        print(\"optimiizing\")\n",
    "        print(type(smac), \"|\", smac)\n",
    "        incumbent = smac.optimize()\n",
    "        print(\"incumbent:\", incumbent)\n",
    "        default_cost = smac.validate(GBT.configspace.get_default_configuration())\n",
    "        print(f\"Default cost ({intensifier.__class__.__name__}): {default_cost}\")\n",
    "        incumbent_cost = smac.validate(incumbent)\n",
    "        print(f\"Incumbent cost ({intensifier.__class__.__name__}): {incumbent_cost}\")\n",
    "\n",
    "        facades.append(smac)\n",
    "        for arrt in dir(smac):\n",
    "            if not arrt.startswith(\"_\"):\n",
    "                print(arrt, getattr(smac, arrt))\n",
    "\n",
    "    print(\"facades:\", facades)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # with open('smac_results_2h.txt', \"w\") as f:\n",
    "    #     pass\n",
    "    profiler = LineProfiler()\n",
    "    profiler.add_function(main)\n",
    "    profiler.enable()\n",
    "\n",
    "    main()\n",
    "\n",
    "    profiler.disable()\n",
    "    profiler.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config dc624a as new incumbent because there are no incumbents yet.\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config 5e35e4 and rejected config dc624a as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 650 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 1050 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1200 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1750 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2300 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2400 trials.\n",
      "[INFO][smbo.py:319] Finished 2600 trials.\n",
      "[INFO][smbo.py:319] Finished 2600 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2950 trials.\n",
      "[INFO][smbo.py:319] Finished 3200 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3450 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3900 trials.\n",
      "[INFO][smbo.py:319] Finished 4000 trials.\n",
      "[INFO][smbo.py:319] Finished 4100 trials.\n",
      "[INFO][smbo.py:319] Finished 4150 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4350 trials.\n",
      "[INFO][smbo.py:319] Finished 4400 trials.\n",
      "[INFO][smbo.py:319] Finished 4500 trials.\n",
      "[INFO][smbo.py:319] Finished 4550 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -0.9153745174407959\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 5428\n",
      "Parameters: {'colsample_bylevel': 0.9701000734994785, 'colsample_bynode': 0.6545724822936216, 'colsample_bytree': 0.5958614671469253, 'gamma': 0.14035844350103893, 'learning_rate': 0.28687548834719934, 'max_depth': 8, 'min_child_weight': 2, 'n_estimators': 1494, 'subsample': 0.6912214484095188}\n",
      "Cost: 0.0 | Config ID: 46\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 01:43:39,481 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36645', name: 5, status: init, memory: 0, processing: 0>\n",
      "2024-09-21 01:43:39,487 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36645\n",
      "2024-09-21 01:43:39,489 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55862\n",
      "2024-09-21 01:43:39,492 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38669', name: 2, status: init, memory: 0, processing: 0>\n",
      "2024-09-21 01:43:39,495 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38669\n",
      "2024-09-21 01:43:39,497 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55842\n",
      "2024-09-21 01:43:39,502 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46335', name: 4, status: init, memory: 0, processing: 0>\n",
      "2024-09-21 01:43:39,505 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46335\n",
      "2024-09-21 01:43:39,507 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55852\n",
      "2024-09-21 01:43:39,512 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37945', name: 3, status: init, memory: 0, processing: 0>\n",
      "2024-09-21 01:43:39,515 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37945\n",
      "2024-09-21 01:43:39,516 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55846\n",
      "2024-09-21 01:43:39,531 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35317', name: 1, status: init, memory: 0, processing: 0>\n",
      "2024-09-21 01:43:39,533 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35317\n",
      "2024-09-21 01:43:39,534 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55828\n",
      "2024-09-21 01:43:39,536 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46477', name: 0, status: init, memory: 0, processing: 0>\n",
      "2024-09-21 01:43:39,539 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46477\n",
      "2024-09-21 01:43:39,540 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55812\n",
      "2024-09-21 01:43:39,624 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37175', name: 6, status: init, memory: 0, processing: 0>\n",
      "2024-09-21 01:43:39,630 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37175\n",
      "2024-09-21 01:43:39,632 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55864\n",
      "2024-09-21 01:43:40,308 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36935', name: 7, status: init, memory: 0, processing: 0>\n",
      "2024-09-21 01:43:40,316 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36935\n",
      "2024-09-21 01:43:40,318 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55878\n",
      "2024-09-21 01:43:40,361 - distributed.scheduler - INFO - Receive client connection: Client-72108754-77dc-11ef-8927-246e9624e1b0\n",
      "2024-09-21 01:43:40,363 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config 92493a as new incumbent because there are no incumbents yet.\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config 9e3203 and rejected config 92493a as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 200 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 650 trials.\n",
      "[INFO][smbo.py:319] Finished 650 trials.\n",
      "[INFO][smbo.py:319] Finished 750 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1150 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1950 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2250 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 3200 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3450 trials.\n",
      "[INFO][smbo.py:319] Finished 3450 trials.\n",
      "[INFO][smbo.py:319] Finished 3450 trials.\n",
      "[INFO][smbo.py:319] Finished 3450 trials.\n",
      "[INFO][smbo.py:319] Finished 3500 trials.\n",
      "[INFO][smbo.py:319] Finished 3500 trials.\n",
      "[INFO][smbo.py:319] Finished 3500 trials.\n",
      "[INFO][smbo.py:319] Finished 3500 trials.\n",
      "[INFO][smbo.py:319] Finished 3500 trials.\n",
      "[INFO][smbo.py:319] Finished 3500 trials.\n",
      "[INFO][smbo.py:319] Finished 3650 trials.\n",
      "[INFO][smbo.py:319] Finished 3650 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 4000 trials.\n",
      "[INFO][smbo.py:319] Finished 4100 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4400 trials.\n",
      "[INFO][smbo.py:319] Finished 4400 trials.\n",
      "[INFO][smbo.py:319] Finished 4400 trials.\n",
      "[INFO][smbo.py:319] Finished 4400 trials.\n",
      "[INFO][smbo.py:319] Finished 4400 trials.\n",
      "[INFO][smbo.py:319] Finished 4400 trials.\n",
      "[INFO][smbo.py:319] Finished 4550 trials.\n",
      "[INFO][smbo.py:319] Finished 4550 trials.\n",
      "[INFO][smbo.py:319] Finished 4550 trials.\n",
      "[INFO][smbo.py:319] Finished 4550 trials.\n",
      "[INFO][smbo.py:319] Finished 4600 trials.\n",
      "[INFO][smbo.py:319] Finished 4600 trials.\n",
      "[INFO][smbo.py:319] Finished 4600 trials.\n",
      "[INFO][smbo.py:319] Finished 4600 trials.\n",
      "[INFO][smbo.py:319] Finished 4600 trials.\n",
      "[INFO][smbo.py:319] Finished 4600 trials.\n",
      "[INFO][smbo.py:319] Finished 4600 trials.\n",
      "[INFO][smbo.py:319] Finished 4700 trials.\n",
      "[INFO][smbo.py:319] Finished 4700 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -6.88780403137207\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 5269\n",
      "Parameters: {'colsample_bylevel': 0.683119850018741, 'colsample_bynode': 0.8595439292367302, 'colsample_bytree': 0.9936804816043545, 'gamma': 0.17841636973138664, 'learning_rate': 0.2996472843928155, 'max_depth': 19, 'min_child_weight': 2, 'n_estimators': 1094, 'subsample': 0.684939858432469}\n",
      "Cost: 0.00019999999999997797 | Config ID: 101\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config 3a27f4 as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config f3cff8 and rejected config 3a27f4 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config d8b3e0 and rejected config f3cff8 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1200 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1750 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1900 trials.\n",
      "[INFO][smbo.py:319] Finished 2050 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2300 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 3200 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3950 trials.\n",
      "[INFO][smbo.py:319] Finished 3950 trials.\n",
      "[INFO][smbo.py:319] Finished 3950 trials.\n",
      "[INFO][smbo.py:319] Finished 4150 trials.\n",
      "[INFO][smbo.py:319] Finished 4200 trials.\n",
      "[INFO][smbo.py:319] Finished 4200 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4400 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -0.25280117988586426\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 5480\n",
      "Parameters: {'colsample_bylevel': 0.6841694527491273, 'colsample_bynode': 0.7521258791466592, 'colsample_bytree': 0.8542075266578653, 'gamma': 0.17841636973138664, 'learning_rate': 0.2936068843275964, 'max_depth': 14, 'min_child_weight': 3, 'n_estimators': 965, 'subsample': 0.679753950286893}\n",
      "Cost: 0.0 | Config ID: 1\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config 364b3a as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config 3b9ad3 and rejected config 364b3a as incumbent because it is not better than the incumbents on 1 instances:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 03:44:10,866 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:47000 remote=tcp://127.0.0.1:43093>: Stream is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_intensifier.py:594] Added config c7d68e and rejected config 3b9ad3 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1050 trials.\n",
      "[INFO][smbo.py:319] Finished 1050 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1200 trials.\n",
      "[INFO][smbo.py:319] Finished 1400 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1700 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2400 trials.\n",
      "[INFO][smbo.py:319] Finished 2450 trials.\n",
      "[INFO][smbo.py:319] Finished 2600 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2850 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2950 trials.\n",
      "[INFO][smbo.py:319] Finished 3200 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3350 trials.\n",
      "[INFO][smbo.py:319] Finished 3500 trials.\n",
      "[INFO][smbo.py:319] Finished 3500 trials.\n",
      "[INFO][smbo.py:319] Finished 3500 trials.\n",
      "[INFO][smbo.py:319] Finished 3600 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3950 trials.\n",
      "[INFO][smbo.py:319] Finished 4000 trials.\n",
      "[INFO][smbo.py:319] Finished 4100 trials.\n",
      "[INFO][smbo.py:319] Finished 4250 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4350 trials.\n",
      "[INFO][smbo.py:319] Finished 4400 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -0.3312101364135742\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 5598\n",
      "Parameters: {'colsample_bylevel': 0.7430921396820616, 'colsample_bynode': 0.6063110478838847, 'colsample_bytree': 0.6832122913577724, 'gamma': 0.11819655769629316, 'learning_rate': 0.26250660140116683, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 1104, 'subsample': 0.6662054557877531}\n",
      "Cost: 0.0 | Config ID: 10\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config 92493a as new incumbent because there are no incumbents yet.\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1150 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1950 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2400 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2850 trials.\n",
      "[INFO][smbo.py:319] Finished 2850 trials.\n",
      "[INFO][smbo.py:319] Finished 2850 trials.\n",
      "[INFO][smbo.py:319] Finished 2850 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3450 trials.\n",
      "[INFO][smbo.py:319] Finished 3500 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 4100 trials.\n",
      "[INFO][smbo.py:319] Finished 4200 trials.\n",
      "[INFO][smbo.py:319] Finished 4200 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -0.720792293548584\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 5604\n",
      "Parameters: {'colsample_bylevel': 0.7110127500129322, 'colsample_bynode': 0.7888818890445719, 'colsample_bytree': 0.8931511066298188, 'gamma': 0.15471634961913655, 'learning_rate': 0.2867980255395253, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 947, 'subsample': 0.6659712486866677}\n",
      "Cost: 0.0 | Config ID: 15\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config b4fb18 as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config 886dc5 and rejected config b4fb18 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 45b6c2 and rejected config 886dc5 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config da35f2 and rejected config 45b6c2 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][smbo.py:319] Finished 300 trials.\n",
      "[INFO][smbo.py:319] Finished 300 trials.\n",
      "[INFO][smbo.py:319] Finished 300 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 750 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1050 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1750 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1950 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2300 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2850 trials.\n",
      "[INFO][smbo.py:319] Finished 2950 trials.\n",
      "[INFO][smbo.py:319] Finished 3150 trials.\n",
      "[INFO][smbo.py:319] Finished 3200 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3450 trials.\n",
      "[INFO][smbo.py:319] Finished 3500 trials.\n",
      "[INFO][smbo.py:319] Finished 3650 trials.\n",
      "[INFO][smbo.py:319] Finished 3650 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3950 trials.\n",
      "[INFO][smbo.py:319] Finished 4000 trials.\n",
      "[INFO][smbo.py:319] Finished 4000 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4400 trials.\n",
      "[INFO][smbo.py:319] Finished 4400 trials.\n",
      "[INFO][smbo.py:319] Finished 4450 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -0.8474586009979248\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 5445\n",
      "Parameters: {'colsample_bylevel': 0.8006325564606935, 'colsample_bynode': 0.6246347243471965, 'colsample_bytree': 0.6702264438270331, 'gamma': 0.14420335635094633, 'learning_rate': 0.23994841070080034, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 974, 'subsample': 0.7279636906646596}\n",
      "Cost: 0.0 | Config ID: 10\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 06:44:17,567 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54070 remote=tcp://127.0.0.1:37057>: Stream is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_intensifier.py:515] Added config dc624a as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config 160a93 and rejected config dc624a as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 200 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 650 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1850 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2400 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 3200 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3350 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3500 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 4050 trials.\n",
      "[INFO][smbo.py:319] Finished 4100 trials.\n",
      "[INFO][smbo.py:319] Finished 4150 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4400 trials.\n",
      "[INFO][smbo.py:319] Finished 4550 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -4.8128907680511475\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 5401\n",
      "Parameters: {'colsample_bylevel': 0.7220678576222633, 'colsample_bynode': 0.8150860310502579, 'colsample_bytree': 0.8655054784519463, 'gamma': 0.10340724860498124, 'learning_rate': 0.28964522191261904, 'max_depth': 13, 'min_child_weight': 6, 'n_estimators': 1111, 'subsample': 0.6821169908409896}\n",
      "Cost: 0.0 | Config ID: 33\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config dc624a as new incumbent because there are no incumbents yet.\n",
      "[INFO][smbo.py:319] Finished 200 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1150 trials.\n",
      "[INFO][smbo.py:319] Finished 1200 trials.\n",
      "[INFO][smbo.py:319] Finished 1300 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:319] Finished 1450 trials.\n",
      "[INFO][smbo.py:319] Finished 1450 trials.\n",
      "[INFO][smbo.py:319] Finished 1450 trials.\n",
      "[INFO][smbo.py:319] Finished 1450 trials.\n",
      "[INFO][smbo.py:319] Finished 1450 trials.\n",
      "[INFO][smbo.py:319] Finished 1450 trials.\n",
      "[INFO][smbo.py:319] Finished 1450 trials.\n",
      "[INFO][smbo.py:319] Finished 1450 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1750 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2300 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2950 trials.\n",
      "[INFO][smbo.py:319] Finished 2950 trials.\n",
      "[INFO][smbo.py:319] Finished 2950 trials.\n",
      "[INFO][smbo.py:319] Finished 2950 trials.\n",
      "[INFO][smbo.py:319] Finished 2950 trials.\n",
      "[INFO][smbo.py:319] Finished 2950 trials.\n",
      "[INFO][smbo.py:319] Finished 2950 trials.\n",
      "[INFO][smbo.py:319] Finished 3500 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -1.1056909561157227\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 5915\n",
      "Parameters: {'colsample_bylevel': 0.6841694527491273, 'colsample_bynode': 0.8150860310502579, 'colsample_bytree': 0.8655054784519463, 'gamma': 0.2573783935536148, 'learning_rate': 0.28815400057691976, 'max_depth': 13, 'min_child_weight': 3, 'n_estimators': 965, 'subsample': 0.679753950286893}\n",
      "Cost: 0.0 | Config ID: 15\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config dc624a as new incumbent because there are no incumbents yet.\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 500 trials.\n",
      "[INFO][smbo.py:319] Finished 500 trials.\n",
      "[INFO][smbo.py:319] Finished 500 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 650 trials.\n",
      "[INFO][smbo.py:319] Finished 700 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1150 trials.\n",
      "[INFO][smbo.py:319] Finished 1200 trials.\n",
      "[INFO][smbo.py:319] Finished 1300 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1750 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2300 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2400 trials.\n",
      "[INFO][smbo.py:319] Finished 2600 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3500 trials.\n",
      "[INFO][smbo.py:319] Finished 3650 trials.\n",
      "[INFO][smbo.py:319] Finished 3650 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3950 trials.\n",
      "[INFO][smbo.py:319] Finished 3950 trials.\n",
      "[INFO][smbo.py:319] Finished 3950 trials.\n",
      "[INFO][smbo.py:319] Finished 4100 trials.\n",
      "[INFO][smbo.py:319] Finished 4100 trials.\n",
      "[INFO][smbo.py:319] Finished 4100 trials.\n",
      "[INFO][smbo.py:319] Finished 4100 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -5.4741432666778564\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 5820\n",
      "Parameters: {'colsample_bylevel': 0.6841694527491273, 'colsample_bynode': 0.8150860310502579, 'colsample_bytree': 0.8655054784519463, 'gamma': 0.2573783935536148, 'learning_rate': 0.28815400057691976, 'max_depth': 13, 'min_child_weight': 3, 'n_estimators': 965, 'subsample': 0.679753950286893}\n",
      "Cost: 0.0 | Config ID: 15\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config 3cd423 as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config 02eaaa and rejected config 3cd423 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 13a552 and rejected config 02eaaa as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 2f7817 and rejected config 13a552 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config d8b3e0 and rejected config 2f7817 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 200 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 650 trials.\n",
      "[INFO][smbo.py:319] Finished 650 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1200 trials.\n",
      "[INFO][smbo.py:319] Finished 1300 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1750 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1950 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2300 trials.\n",
      "[INFO][smbo.py:319] Finished 2300 trials.\n",
      "[INFO][smbo.py:319] Finished 2300 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2400 trials.\n",
      "[INFO][smbo.py:319] Finished 2500 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2850 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 3150 trials.\n",
      "[INFO][smbo.py:319] Finished 3200 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3450 trials.\n",
      "[INFO][smbo.py:319] Finished 3550 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3800 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 4300 trials.\n",
      "[INFO][smbo.py:319] Finished 4400 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -6.532792568206787\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 5502\n",
      "Parameters: {'colsample_bylevel': 0.6841694527491273, 'colsample_bynode': 0.7521258791466592, 'colsample_bytree': 0.8542075266578653, 'gamma': 0.17841636973138664, 'learning_rate': 0.2936068843275964, 'max_depth': 14, 'min_child_weight': 3, 'n_estimators': 965, 'subsample': 0.679753950286893}\n",
      "Cost: 0.0 | Config ID: 1\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config 92493a as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config d8b3e0 and rejected config 92493a as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config c2f4eb and rejected config d8b3e0 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config a8c369 and rejected config c2f4eb as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config e277c5 and rejected config a8c369 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config bfcd2c and rejected config e277c5 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 39fe4f and rejected config bfcd2c as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config 0cac20 and rejected config 39fe4f as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 650 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1200 trials.\n",
      "[INFO][smbo.py:319] Finished 1250 trials.\n",
      "[INFO][smbo.py:319] Finished 1250 trials.\n",
      "[INFO][smbo.py:319] Finished 1250 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1850 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2400 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2950 trials.\n",
      "[INFO][smbo.py:319] Finished 3050 trials.\n",
      "[INFO][smbo.py:319] Finished 3050 trials.\n",
      "[INFO][smbo.py:319] Finished 3050 trials.\n",
      "[INFO][smbo.py:319] Finished 3200 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3650 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 4000 trials.\n",
      "[INFO][smbo.py:319] Finished 4000 trials.\n",
      "[INFO][smbo.py:319] Finished 4000 trials.\n",
      "[INFO][smbo.py:319] Finished 4000 trials.\n",
      "[INFO][smbo.py:319] Finished 4050 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -3.018230676651001\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 5766\n",
      "Parameters: {'colsample_bylevel': 0.8216300899307534, 'colsample_bynode': 0.7649389691438414, 'colsample_bytree': 0.8645021785211531, 'gamma': 0.10011315252709926, 'learning_rate': 0.27191218765262026, 'max_depth': 14, 'min_child_weight': 1, 'n_estimators': 1132, 'subsample': 0.7204996718071182}\n",
      "Cost: 0.012599999999999945 | Config ID: 199\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config dc624a as new incumbent because there are no incumbents yet.\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 850 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1200 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:319] Finished 1450 trials.\n",
      "[INFO][smbo.py:319] Finished 1450 trials.\n",
      "[INFO][smbo.py:319] Finished 1450 trials.\n",
      "[INFO][smbo.py:319] Finished 1450 trials.\n",
      "[INFO][smbo.py:319] Finished 1450 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1750 trials.\n",
      "[INFO][smbo.py:319] Finished 1850 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2300 trials.\n",
      "[INFO][smbo.py:319] Finished 2550 trials.\n",
      "[INFO][smbo.py:319] Finished 2550 trials.\n",
      "[INFO][smbo.py:319] Finished 2550 trials.\n",
      "[INFO][smbo.py:319] Finished 2550 trials.\n",
      "[INFO][smbo.py:319] Finished 2550 trials.\n",
      "[INFO][smbo.py:319] Finished 2550 trials.\n",
      "[INFO][smbo.py:319] Finished 2550 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2850 trials.\n",
      "[INFO][smbo.py:319] Finished 3050 trials.\n",
      "[INFO][smbo.py:319] Finished 3050 trials.\n",
      "[INFO][smbo.py:319] Finished 3050 trials.\n",
      "[INFO][smbo.py:319] Finished 3050 trials.\n",
      "[INFO][smbo.py:319] Finished 3050 trials.\n",
      "[INFO][smbo.py:319] Finished 3050 trials.\n",
      "[INFO][smbo.py:319] Finished 3050 trials.\n",
      "[INFO][smbo.py:319] Finished 3200 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3350 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -6.620331764221191\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 6635\n",
      "Parameters: {'colsample_bylevel': 0.6841694527491273, 'colsample_bynode': 0.8150860310502579, 'colsample_bytree': 0.8655054784519463, 'gamma': 0.2573783935536148, 'learning_rate': 0.28815400057691976, 'max_depth': 13, 'min_child_weight': 3, 'n_estimators': 965, 'subsample': 0.679753950286893}\n",
      "Cost: 0.0 | Config ID: 15\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config 98029a as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config 12ac50 and rejected config 98029a as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config 482f73 and rejected config 12ac50 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][smbo.py:319] Finished 200 trials.\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1900 trials.\n",
      "[INFO][smbo.py:319] Finished 1900 trials.\n",
      "[INFO][smbo.py:319] Finished 1900 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2600 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2850 trials.\n",
      "[INFO][smbo.py:319] Finished 3200 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3550 trials.\n",
      "[INFO][smbo.py:319] Finished 3650 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3800 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3900 trials.\n",
      "[INFO][smbo.py:319] Finished 3950 trials.\n",
      "[INFO][smbo.py:319] Finished 3950 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -1.5050549507141113\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 6030\n",
      "Parameters: {'colsample_bylevel': 0.7214660285659258, 'colsample_bynode': 0.7914714437821726, 'colsample_bytree': 0.9817972653401712, 'gamma': 0.1286863222339306, 'learning_rate': 0.2998333835855037, 'max_depth': 12, 'min_child_weight': 1, 'n_estimators': 1167, 'subsample': 0.6515952524147529}\n",
      "Cost: 0.0010000000000000009 | Config ID: 67\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config 70e4f7 as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config cadd79 and rejected config 70e4f7 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config df3a3f and rejected config cadd79 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1150 trials.\n",
      "[INFO][smbo.py:319] Finished 1300 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1750 trials.\n",
      "[INFO][smbo.py:319] Finished 1900 trials.\n",
      "[INFO][smbo.py:319] Finished 2000 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2450 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 3050 trials.\n",
      "[INFO][smbo.py:319] Finished 3050 trials.\n",
      "[INFO][smbo.py:319] Finished 3050 trials.\n",
      "[INFO][smbo.py:319] Finished 3050 trials.\n",
      "[INFO][smbo.py:319] Finished 3050 trials.\n",
      "[INFO][smbo.py:319] Finished 3050 trials.\n",
      "[INFO][smbo.py:319] Finished 3050 trials.\n",
      "[INFO][smbo.py:319] Finished 3150 trials.\n",
      "[INFO][smbo.py:319] Finished 3200 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -0.5444686412811279\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 6735\n",
      "Parameters: {'colsample_bylevel': 0.7241537883153844, 'colsample_bynode': 0.7386172930489208, 'colsample_bytree': 0.8609408932603022, 'gamma': 0.19332801435763922, 'learning_rate': 0.2936068843275964, 'max_depth': 10, 'min_child_weight': 9, 'n_estimators': 1006, 'subsample': 0.679753950286893}\n",
      "Cost: 0.0 | Config ID: 13\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config 6a7ab2 as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config 17c431 and rejected config 6a7ab2 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 774581 and rejected config 17c431 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][smbo.py:319] Finished 200 trials.\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 650 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1300 trials.\n",
      "[INFO][smbo.py:319] Finished 1400 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1850 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2150 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2400 trials.\n",
      "[INFO][smbo.py:319] Finished 2500 trials.\n",
      "[INFO][smbo.py:319] Finished 2500 trials.\n",
      "[INFO][smbo.py:319] Finished 2600 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2850 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2950 trials.\n",
      "[INFO][smbo.py:319] Finished 3200 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3450 trials.\n",
      "[INFO][smbo.py:319] Finished 3500 trials.\n",
      "[INFO][smbo.py:319] Finished 3550 trials.\n",
      "[INFO][smbo.py:319] Finished 3650 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3800 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3900 trials.\n",
      "[INFO][smbo.py:319] Finished 3900 trials.\n",
      "[INFO][smbo.py:319] Finished 4000 trials.\n",
      "[INFO][smbo.py:319] Finished 4000 trials.\n",
      "[INFO][smbo.py:319] Finished 4000 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -6.426926612854004\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 5986\n",
      "Parameters: {'colsample_bylevel': 0.7758169377125658, 'colsample_bynode': 0.910903134837318, 'colsample_bytree': 0.9302721868845663, 'gamma': 0.16623758437498093, 'learning_rate': 0.24262108814138053, 'max_depth': 14, 'min_child_weight': 5, 'n_estimators': 1095, 'subsample': 0.6180071666974086}\n",
      "Cost: 0.0 | Config ID: 10\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config 78265d as new incumbent because there are no incumbents yet.\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 700 trials.\n",
      "[INFO][smbo.py:319] Finished 750 trials.\n",
      "[INFO][smbo.py:319] Finished 850 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1150 trials.\n",
      "[INFO][smbo.py:319] Finished 1200 trials.\n",
      "[INFO][smbo.py:319] Finished 1250 trials.\n",
      "[INFO][smbo.py:319] Finished 1500 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1850 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2300 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2600 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 2900 trials.\n",
      "[INFO][smbo.py:319] Finished 3050 trials.\n",
      "[INFO][smbo.py:319] Finished 3050 trials.\n",
      "[INFO][smbo.py:319] Finished 3150 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3300 trials.\n",
      "[INFO][smbo.py:319] Finished 3400 trials.\n",
      "[INFO][smbo.py:319] Finished 3450 trials.\n",
      "[INFO][smbo.py:319] Finished 3450 trials.\n",
      "[INFO][smbo.py:319] Finished 3450 trials.\n",
      "[INFO][smbo.py:319] Finished 3450 trials.\n",
      "[INFO][smbo.py:319] Finished 3500 trials.\n",
      "[INFO][smbo.py:319] Finished 3600 trials.\n",
      "[INFO][smbo.py:319] Finished 3650 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3750 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:319] Finished 3850 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -0.3142664432525635\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 6088\n",
      "Parameters: {'colsample_bylevel': 0.7029277180375672, 'colsample_bynode': 0.89504363298756, 'colsample_bytree': 0.5837150489199923, 'gamma': 0.16084935479957832, 'learning_rate': 0.24649337993615708, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 1250, 'subsample': 0.6733856412972936}\n",
      "Cost: 0.027800000000000047 | Config ID: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 17:04:42,356 - distributed.scheduler - INFO - Remove client Client-181a0878-7852-11ef-8927-246e9624e1b0\n",
      "2024-09-21 17:04:42,358 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40116; closing.\n",
      "2024-09-21 17:04:42,364 - distributed.scheduler - INFO - Remove client Client-181a0878-7852-11ef-8927-246e9624e1b0\n",
      "2024-09-21 17:04:42,368 - distributed.scheduler - INFO - Close client connection: Client-181a0878-7852-11ef-8927-246e9624e1b0\n",
      "2024-09-21 17:04:42,375 - distributed.scheduler - INFO - Retire worker addresses (0, 1, 2, 3, 4, 5, 6, 7)\n",
      "2024-09-21 17:04:42,379 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34023'. Reason: nanny-close\n",
      "2024-09-21 17:04:42,383 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-09-21 17:04:42,384 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33845'. Reason: nanny-close\n",
      "2024-09-21 17:04:42,387 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-09-21 17:04:42,388 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46627'. Reason: nanny-close\n",
      "2024-09-21 17:04:42,390 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-09-21 17:04:42,392 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37397'. Reason: nanny-close\n",
      "2024-09-21 17:04:42,396 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-09-21 17:04:42,398 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40135'. Reason: nanny-close\n",
      "2024-09-21 17:04:42,400 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-09-21 17:04:42,402 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41043'. Reason: nanny-close\n",
      "2024-09-21 17:04:42,405 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-09-21 17:04:42,406 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44997'. Reason: nanny-close\n",
      "2024-09-21 17:04:42,409 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-09-21 17:04:42,410 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44653'. Reason: nanny-close\n",
      "2024-09-21 17:04:42,413 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-09-21 17:04:42,426 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40056; closing.\n",
      "2024-09-21 17:04:42,428 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40064; closing.\n",
      "2024-09-21 17:04:42,429 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40066; closing.\n",
      "2024-09-21 17:04:42,431 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40080; closing.\n",
      "2024-09-21 17:04:42,433 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40082; closing.\n",
      "2024-09-21 17:04:42,434 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40088; closing.\n",
      "2024-09-21 17:04:42,436 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40092; closing.\n",
      "2024-09-21 17:04:42,438 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41219', name: 0, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1726952682.4383335')\n",
      "2024-09-21 17:04:42,440 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36751', name: 1, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1726952682.4401362')\n",
      "2024-09-21 17:04:42,441 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37823', name: 2, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1726952682.4418967')\n",
      "2024-09-21 17:04:42,443 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44681', name: 3, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1726952682.443359')\n",
      "2024-09-21 17:04:42,445 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33315', name: 4, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1726952682.4450684')\n",
      "2024-09-21 17:04:42,446 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34607', name: 5, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1726952682.4463701')\n",
      "2024-09-21 17:04:42,447 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42013', name: 6, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1726952682.4477704')\n",
      "2024-09-21 17:04:42,449 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40102; closing.\n",
      "2024-09-21 17:04:42,456 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36307', name: 7, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1726952682.4565117')\n",
      "2024-09-21 17:04:42,458 - distributed.scheduler - INFO - Lost all workers\n",
      "2024-09-21 17:04:42,460 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:33175 remote=tcp://127.0.0.1:40102>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/batched.py\", line 115, in _background_send\n",
      "    nbytes = yield coro\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/tornado/gen.py\", line 767, in run\n",
      "    value = future.result()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-21 17:04:42,766 - distributed.scheduler - INFO - Scheduler closing due to unknown reason...\n",
      "2024-09-21 17:04:42,769 - distributed.scheduler - INFO - Scheduler closing all comms\n"
     ]
    }
   ],
   "source": [
    "params_dict_XGBT = {}\n",
    "for i in range(len(train_x_list)):\n",
    "    train_x = train_x_list[i]\n",
    "    train_y = train_y_list[i]\n",
    "    \n",
    "    class XGBTWrapper(BaseEstimator):\n",
    "        def __init__(self, n_estimators=100, max_depth=2, seed= 317, min_child_weight=1, gamma=0.1, subsample=0.8, colsample_bytree=0.5, learning_rate=0.1, objective='binary:logistic', colsample_bylevel=0.5, colsample_bynode=0.5):\n",
    "            self.n_estimators = n_estimators\n",
    "            self.max_depth = max_depth\n",
    "            self.seed= seed\n",
    "            self.min_child_weight = min_child_weight\n",
    "            self.gamma = gamma\n",
    "            self.subsample = subsample\n",
    "            self.colsample_bytree = colsample_bytree\n",
    "            self.colsample_bylevel = colsample_bylevel\n",
    "            self.colsample_bynode = colsample_bynode\n",
    "            self.learning_rate = learning_rate\n",
    "            self.objective = objective\n",
    "            # self.num_class = num_class\n",
    "            self.model = xgb.XGBClassifier(n_estimators=self.n_estimators, max_depth=self.max_depth, seed=self.seed, min_child_weight=self.min_child_weight, gamma=self.gamma, subsample=self.subsample, colsample_bytree=self.colsample_bytree, colsample_bylevel=self.colsample_bylevel, colsample_bynode=self.colsample_bynode ,learning_rate=self.learning_rate, objective=self.objective)\n",
    "\n",
    "        @property\n",
    "        def configspace(self) -> ConfigurationSpace:\n",
    "            cs = ConfigurationSpace()\n",
    "            n_estimators = Integer(\"n_estimators\", (100, 1500), default=100)\n",
    "            max_depth = Integer(\"max_depth\", (2, 21), default=2)\n",
    "            min_child_weight = Integer(\"min_child_weight\", (1, 10), default=1)\n",
    "            gamma = Float(\"gamma\", (0.1, 1.0), default=0.1)\n",
    "            subsample = Float(\"subsample\", (0.5, 1.0), default=0.8)\n",
    "            colsample_bytree = Float(\"colsample_bytree\", (0.3, 1.0), default=0.6)\n",
    "            colsample_bylevel = Float(\"colsample_bylevel\", (0.3, 1.0), default=0.6)\n",
    "            colsample_bynode = Float(\"colsample_bynode\", (0.3, 1.0), default=0.6)\n",
    "            learning_rate = Float(\"learning_rate\", (0.001, 0.3), default=0.1)\n",
    "            cs.add_hyperparameters([n_estimators, max_depth, min_child_weight, gamma, subsample, colsample_bytree, colsample_bylevel, colsample_bynode, learning_rate])\n",
    "            return cs\n",
    "        \n",
    "        def fit(self, config: Configuration, seed: int = 0, budget: int = 250) -> float: \n",
    "            config = dict(config)  \n",
    "            self.model.set_params(**config)\n",
    "            X = train_x\n",
    "            y = train_y\n",
    "            # print(\"X shape: \", X.shape)\n",
    "            # print(\"y shape: \", y.shape)\n",
    "            self.model.fit(X, y)\n",
    "            preds = self.model.predict(X)\n",
    "            scores = accuracy_score(y, preds)\n",
    "            \n",
    "            return 1 - scores\n",
    "\n",
    "    # @timeout(900)\n",
    "    def main():\n",
    "        GBT = XGBTWrapper()\n",
    "\n",
    "        facades: list[AbstractFacade] = []\n",
    "        for intensifier_object in [Hyperband]:\n",
    "\n",
    "            scenario = Scenario(\n",
    "                GBT.configspace,\n",
    "                walltime_limit=3600,\n",
    "                output_directory=Path(\"smac_hyperband_output_budget_1hr_XGBT_337/\" + dataset_names[i]),\n",
    "                n_trials=10000,\n",
    "                min_budget=100,\n",
    "                max_budget=1000,\n",
    "                n_workers=8,\n",
    "\n",
    "            )\n",
    "\n",
    "            initial_design = MFFacade.get_initial_design(scenario, n_configs=5)\n",
    "            intensifier = intensifier_object(scenario, incumbent_selection=\"highest_budget\")\n",
    "\n",
    "            smac = MFFacade(\n",
    "                scenario,\n",
    "                GBT.fit,\n",
    "                initial_design=initial_design,\n",
    "                intensifier=intensifier,\n",
    "                overwrite=True,\n",
    "            )\n",
    "\n",
    "            print(\"optimizing\")\n",
    "            # print(type(smac), \"|\", smac)\n",
    "            incumbent = smac.optimize()\n",
    "            best_params = incumbent.get_dictionary()\n",
    "            params_dict_XGBT[dataset_names[i]] = best_params\n",
    "\n",
    "            incumbent_cost = smac.runhistory.get_cost(incumbent)\n",
    "            incumbent_run_id = incumbent.config_id\n",
    "\n",
    "            print(f\"Parameters: {best_params}\")\n",
    "            print(f\"Cost: {incumbent_cost} | Config ID: {incumbent_run_id}\")\n",
    "\n",
    "            default_cost = smac.validate(GBT.configspace.get_default_configuration())\n",
    "            # print(f\"Default cost ({intensifier.__class__.__name__}): {default_cost}\")\n",
    "            incumbent_cost = smac.validate(incumbent)\n",
    "            # print(f\"Incumbent cost ({intensifier.__class__.__name__}): {incumbent_cost}\")\n",
    "\n",
    "            facades.append(smac)\n",
    "        #     for arrt in dir(smac):\n",
    "        #         if not arrt.startswith(\"_\"):\n",
    "        #             print(arrt, getattr(smac, arrt))\n",
    "\n",
    "        # print(\"facades:\", facades)\n",
    "\n",
    "\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        # with open('smac_results_2h.txt', \"w\") as f:\n",
    "        #     pass\n",
    "        # profiler = LineProfiler()\n",
    "        # profiler.add_function(main)\n",
    "        # profiler.enable()\n",
    "\n",
    "        main()\n",
    "\n",
    "        # profiler.disable()\n",
    "        # profiler.print_stats()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: credit, Best Parameters: {'colsample_bylevel': 0.9701000734994785, 'colsample_bynode': 0.6545724822936216, 'colsample_bytree': 0.5958614671469253, 'gamma': 0.14035844350103893, 'learning_rate': 0.28687548834719934, 'max_depth': 8, 'min_child_weight': 2, 'n_estimators': 1494, 'subsample': 0.6912214484095188}\n",
      "Dataset: electricity, Best Parameters: {'colsample_bylevel': 0.683119850018741, 'colsample_bynode': 0.8595439292367302, 'colsample_bytree': 0.9936804816043545, 'gamma': 0.17841636973138664, 'learning_rate': 0.2996472843928155, 'max_depth': 19, 'min_child_weight': 2, 'n_estimators': 1094, 'subsample': 0.684939858432469}\n",
      "Dataset: covertype, Best Parameters: {'colsample_bylevel': 0.6841694527491273, 'colsample_bynode': 0.7521258791466592, 'colsample_bytree': 0.8542075266578653, 'gamma': 0.17841636973138664, 'learning_rate': 0.2936068843275964, 'max_depth': 14, 'min_child_weight': 3, 'n_estimators': 965, 'subsample': 0.679753950286893}\n",
      "Dataset: pol, Best Parameters: {'colsample_bylevel': 0.7430921396820616, 'colsample_bynode': 0.6063110478838847, 'colsample_bytree': 0.6832122913577724, 'gamma': 0.11819655769629316, 'learning_rate': 0.26250660140116683, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 1104, 'subsample': 0.6662054557877531}\n",
      "Dataset: house_16H, Best Parameters: {'colsample_bylevel': 0.7110127500129322, 'colsample_bynode': 0.7888818890445719, 'colsample_bytree': 0.8931511066298188, 'gamma': 0.15471634961913655, 'learning_rate': 0.2867980255395253, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 947, 'subsample': 0.6659712486866677}\n",
      "Dataset: MagicTelescope, Best Parameters: {'colsample_bylevel': 0.8006325564606935, 'colsample_bynode': 0.6246347243471965, 'colsample_bytree': 0.6702264438270331, 'gamma': 0.14420335635094633, 'learning_rate': 0.23994841070080034, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 974, 'subsample': 0.7279636906646596}\n",
      "Dataset: bank-marketing, Best Parameters: {'colsample_bylevel': 0.7220678576222633, 'colsample_bynode': 0.8150860310502579, 'colsample_bytree': 0.8655054784519463, 'gamma': 0.10340724860498124, 'learning_rate': 0.28964522191261904, 'max_depth': 13, 'min_child_weight': 6, 'n_estimators': 1111, 'subsample': 0.6821169908409896}\n",
      "Dataset: MiniBooNE, Best Parameters: {'colsample_bylevel': 0.6841694527491273, 'colsample_bynode': 0.8150860310502579, 'colsample_bytree': 0.8655054784519463, 'gamma': 0.2573783935536148, 'learning_rate': 0.28815400057691976, 'max_depth': 13, 'min_child_weight': 3, 'n_estimators': 965, 'subsample': 0.679753950286893}\n",
      "Dataset: Higgs, Best Parameters: {'colsample_bylevel': 0.6841694527491273, 'colsample_bynode': 0.8150860310502579, 'colsample_bytree': 0.8655054784519463, 'gamma': 0.2573783935536148, 'learning_rate': 0.28815400057691976, 'max_depth': 13, 'min_child_weight': 3, 'n_estimators': 965, 'subsample': 0.679753950286893}\n",
      "Dataset: eye_movements, Best Parameters: {'colsample_bylevel': 0.6841694527491273, 'colsample_bynode': 0.7521258791466592, 'colsample_bytree': 0.8542075266578653, 'gamma': 0.17841636973138664, 'learning_rate': 0.2936068843275964, 'max_depth': 14, 'min_child_weight': 3, 'n_estimators': 965, 'subsample': 0.679753950286893}\n",
      "Dataset: Diabetes130US, Best Parameters: {'colsample_bylevel': 0.8216300899307534, 'colsample_bynode': 0.7649389691438414, 'colsample_bytree': 0.8645021785211531, 'gamma': 0.10011315252709926, 'learning_rate': 0.27191218765262026, 'max_depth': 14, 'min_child_weight': 1, 'n_estimators': 1132, 'subsample': 0.7204996718071182}\n",
      "Dataset: jannis, Best Parameters: {'colsample_bylevel': 0.6841694527491273, 'colsample_bynode': 0.8150860310502579, 'colsample_bytree': 0.8655054784519463, 'gamma': 0.2573783935536148, 'learning_rate': 0.28815400057691976, 'max_depth': 13, 'min_child_weight': 3, 'n_estimators': 965, 'subsample': 0.679753950286893}\n",
      "Dataset: default-of-credit-card-clients, Best Parameters: {'colsample_bylevel': 0.7214660285659258, 'colsample_bynode': 0.7914714437821726, 'colsample_bytree': 0.9817972653401712, 'gamma': 0.1286863222339306, 'learning_rate': 0.2998333835855037, 'max_depth': 12, 'min_child_weight': 1, 'n_estimators': 1167, 'subsample': 0.6515952524147529}\n",
      "Dataset: Bioresponse, Best Parameters: {'colsample_bylevel': 0.7241537883153844, 'colsample_bynode': 0.7386172930489208, 'colsample_bytree': 0.8609408932603022, 'gamma': 0.19332801435763922, 'learning_rate': 0.2936068843275964, 'max_depth': 10, 'min_child_weight': 9, 'n_estimators': 1006, 'subsample': 0.679753950286893}\n",
      "Dataset: california, Best Parameters: {'colsample_bylevel': 0.7758169377125658, 'colsample_bynode': 0.910903134837318, 'colsample_bytree': 0.9302721868845663, 'gamma': 0.16623758437498093, 'learning_rate': 0.24262108814138053, 'max_depth': 14, 'min_child_weight': 5, 'n_estimators': 1095, 'subsample': 0.6180071666974086}\n",
      "Dataset: heloc, Best Parameters: {'colsample_bylevel': 0.7029277180375672, 'colsample_bynode': 0.89504363298756, 'colsample_bytree': 0.5837150489199923, 'gamma': 0.16084935479957832, 'learning_rate': 0.24649337993615708, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 1250, 'subsample': 0.6733856412972936}\n"
     ]
    }
   ],
   "source": [
    "for dataset, params in params_dict_XGBT.items():\n",
    "    print(f\"Dataset: {dataset}, Best Parameters: {params}\")\n",
    "    # print(f\"Best Parameters: {params}\")\n",
    "with open(\"SmacResults/337/XGBT_params_1hr.json\", 'w') as f:\n",
    "    json.dump(params_dict_XGBT, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFWrapper(BaseEstimator):\n",
    "    def __init__(self, n_estimators=100, max_depth=2, random_state=317, min_samples_split=2, min_samples_leaf=1, max_features=None, criterion=\"gini\", max_samples = 0.5):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features   \n",
    "        self.criterion = \"gini\"\n",
    "        self.max_samples = max_samples\n",
    "        self.model = RandomForestClassifier(n_estimators=self.n_estimators, max_depth=self.max_depth, random_state=self.random_state, min_samples_split=self.min_samples_split, min_samples_leaf=self.min_samples_leaf, criterion=self.criterion, max_features=self.max_features, max_samples=self.max_samples)\n",
    "\n",
    "    @property\n",
    "    def configspace(self) -> ConfigurationSpace:\n",
    "        cs = ConfigurationSpace()\n",
    "        n_estimators = Integer(\"n_estimators\", (100, 1200), default=100)\n",
    "        max_depth = Integer(\"max_depth\", (2,21), default=2)\n",
    "        min_samples_split = Integer(\"min_samples_split\", (2, 20), default=2)\n",
    "        min_samples_leaf = Integer(\"min_samples_leaf\", (1, 20), default=1)\n",
    "        criterion = Categorical(\"criterion\", [\"gini\", \"entropy\", \"log_loss\"], default=\"gini\")\n",
    "        max_features = Categorical(\"max_features\", [\"sqrt\", \"log2\", \"None\"], default=\"None\")\n",
    "        max_samples = Float(\"max_samples\", (0.1, 0.99), log=True)\n",
    "        cs.add_hyperparameters([n_estimators, max_depth, min_samples_split, min_samples_leaf, criterion, max_features, max_samples])\n",
    "        return cs\n",
    "    \n",
    "    def fit(self, config: Configuration, seed: int = 0, budget: int = 250) -> float: \n",
    "        config = dict(config)  \n",
    "        if config['max_features'] == 'None':\n",
    "            config['max_features'] = None\n",
    "        self.model.set_params(**config)\n",
    "        X = train_x\n",
    "        y = train_y\n",
    "        self.model.fit(X, y)\n",
    "        preds = self.model.predict(X)\n",
    "        scores = accuracy_score(y, preds)\n",
    "\n",
    "        return 1 - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeout(900)\n",
    "def main():\n",
    "    RF = RFWrapper()\n",
    "\n",
    "    facades: list[AbstractFacade] = []\n",
    "    for intensifier_object in [Hyperband]:\n",
    "\n",
    "        scenario = Scenario(\n",
    "            RF.configspace,\n",
    "            walltime_limit=600,\n",
    "            output_directory=Path(\"smac_hyperband_output_budget_10mins_RF\"),\n",
    "            n_trials=10000,\n",
    "            min_budget=100,\n",
    "            max_budget=1000,\n",
    "            n_workers=8,\n",
    "\n",
    "        )\n",
    "\n",
    "        initial_design = MFFacade.get_initial_design(scenario, n_configs=5)\n",
    "        intensifier = intensifier_object(scenario, incumbent_selection=\"highest_budget\")\n",
    "\n",
    "        smac = MFFacade(\n",
    "            scenario,\n",
    "            RF.fit,\n",
    "            initial_design=initial_design,\n",
    "            intensifier=intensifier,\n",
    "            overwrite=True,\n",
    "        )\n",
    "\n",
    "        print(\"optimiizing\")\n",
    "        print(type(smac), \"|\", smac)\n",
    "        incumbent = smac.optimize()\n",
    "        print(\"incumbent:\", incumbent)\n",
    "        default_cost = smac.validate(RF.configspace.get_default_configuration())\n",
    "        print(f\"Default cost ({intensifier.__class__.__name__}): {default_cost}\")\n",
    "        incumbent_cost = smac.validate(incumbent)\n",
    "        print(f\"Incumbent cost ({intensifier.__class__.__name__}): {incumbent_cost}\")\n",
    "\n",
    "        facades.append(smac)\n",
    "        for arrt in dir(smac):\n",
    "            if not arrt.startswith(\"_\"):\n",
    "                print(arrt, getattr(smac, arrt))\n",
    "\n",
    "    print(\"facades:\", facades)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # with open('smac_results_2h.txt', \"w\") as f:\n",
    "    #     pass\n",
    "    profiler = LineProfiler()\n",
    "    profiler.add_function(main)\n",
    "    profiler.enable()\n",
    "\n",
    "    main()\n",
    "\n",
    "    profiler.disable()\n",
    "    profiler.print_stats()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimiizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config ec8d41 as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config cebd74 and rejected config ec8d41 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 1a5921 and rejected config cebd74 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config e3b1be and rejected config 1a5921 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config f732f8 and rejected config e3b1be as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 32e678 and rejected config f732f8 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config b58a5b and rejected config 32e678 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 2d007f and rejected config b58a5b as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 200 trials.\n",
      "[INFO][smbo.py:319] Finished 200 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config 9f0554 and rejected config 2d007f as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 500 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 700 trials.\n",
      "[INFO][smbo.py:319] Finished 750 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 850 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 1050 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1250 trials.\n",
      "[INFO][smbo.py:319] Finished 1300 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:319] Finished 1400 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1600 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1700 trials.\n",
      "[INFO][smbo.py:319] Finished 1700 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1850 trials.\n",
      "[INFO][smbo.py:319] Finished 1900 trials.\n",
      "[INFO][smbo.py:319] Finished 2000 trials.\n",
      "[INFO][smbo.py:319] Finished 2050 trials.\n",
      "[INFO][smbo.py:319] Finished 2050 trials.\n",
      "[INFO][smbo.py:319] Finished 2150 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2250 trials.\n",
      "[INFO][smbo.py:319] Finished 2300 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2450 trials.\n",
      "[INFO][smbo.py:319] Finished 2500 trials.\n",
      "[INFO][smbo.py:319] Finished 2600 trials.\n",
      "[INFO][smbo.py:319] Finished 2600 trials.\n",
      "[INFO][smbo.py:319] Finished 2600 trials.\n",
      "[INFO][smbo.py:319] Finished 2600 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2700 trials.\n",
      "[INFO][smbo.py:319] Finished 2700 trials.\n",
      "[INFO][smbo.py:319] Finished 2700 trials.\n",
      "[INFO][smbo.py:319] Finished 2700 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2800 trials.\n",
      "[INFO][smbo.py:319] Finished 2850 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -0.2580986022949219\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 7016\n",
      "Parameters: {'criterion': 'entropy', 'max_depth': 20, 'max_features': 'sqrt', 'max_samples': 0.9691083523958117, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 252}\n",
      "Cost: 0.0 | Config ID: 165\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimiizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config ec8d41 as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config 1a5921 and rejected config ec8d41 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config e3b1be and rejected config 1a5921 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 9f6b2e and rejected config e3b1be as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config a91461 and rejected config 9f6b2e as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 8e32e7 and rejected config a91461 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 2fe56b and rejected config 8e32e7 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config 363586 and rejected config 2fe56b as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 080f61 and rejected config 363586 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 47f1cd and rejected config 080f61 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 200 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 500 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 700 trials.\n",
      "[INFO][smbo.py:319] Finished 750 trials.\n",
      "[INFO][smbo.py:319] Finished 750 trials.\n",
      "[INFO][smbo.py:319] Finished 750 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 850 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 1050 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1150 trials.\n",
      "[INFO][smbo.py:319] Finished 1250 trials.\n",
      "[INFO][smbo.py:319] Finished 1300 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:319] Finished 1400 trials.\n",
      "[INFO][smbo.py:319] Finished 1450 trials.\n",
      "[INFO][smbo.py:319] Finished 1500 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1600 trials.\n",
      "[INFO][smbo.py:319] Finished 1600 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1700 trials.\n",
      "[INFO][smbo.py:319] Finished 1750 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1900 trials.\n",
      "[INFO][smbo.py:319] Finished 1950 trials.\n",
      "[INFO][smbo.py:319] Finished 2000 trials.\n",
      "[INFO][smbo.py:319] Finished 2050 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2150 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2250 trials.\n",
      "[INFO][smbo.py:319] Finished 2300 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2450 trials.\n",
      "[INFO][smbo.py:319] Finished 2500 trials.\n",
      "[INFO][smbo.py:319] Finished 2550 trials.\n",
      "[INFO][smbo.py:319] Finished 2600 trials.\n",
      "[INFO][smbo.py:319] Finished 2700 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -0.33290648460388184\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 7251\n",
      "Parameters: {'criterion': 'gini', 'max_depth': 20, 'max_features': 'log2', 'max_samples': 0.9647413210898548, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 108}\n",
      "Cost: 0.0 | Config ID: 153\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimiizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config ec8d41 as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config 1a5921 and rejected config ec8d41 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config e3b1be and rejected config 1a5921 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config 0c045c and rejected config e3b1be as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 2c53d9 and rejected config 0c045c as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config 774b7f and rejected config 2c53d9 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config b04c4b and rejected config 774b7f as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 39b7ab and rejected config b04c4b as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config bba770 and rejected config 39b7ab as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 300 trials.\n",
      "[INFO][smbo.py:319] Finished 300 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 500 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 650 trials.\n",
      "[INFO][smbo.py:319] Finished 750 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 850 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 1050 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1150 trials.\n",
      "[INFO][smbo.py:319] Finished 1250 trials.\n",
      "[INFO][smbo.py:319] Finished 1300 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:319] Finished 1400 trials.\n",
      "[INFO][smbo.py:319] Finished 1450 trials.\n",
      "[INFO][smbo.py:319] Finished 1500 trials.\n",
      "[INFO][smbo.py:319] Finished 1500 trials.\n",
      "[INFO][smbo.py:319] Finished 1500 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1600 trials.\n",
      "[INFO][smbo.py:319] Finished 1600 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1750 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1850 trials.\n",
      "[INFO][smbo.py:319] Finished 1900 trials.\n",
      "[INFO][smbo.py:319] Finished 2000 trials.\n",
      "[INFO][smbo.py:319] Finished 2050 trials.\n",
      "[INFO][smbo.py:319] Finished 2050 trials.\n",
      "[INFO][smbo.py:319] Finished 2050 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2150 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -0.5681467056274414\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 7826\n",
      "Parameters: {'criterion': 'gini', 'max_depth': 21, 'max_features': 'sqrt', 'max_samples': 0.9847607906550341, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 302}\n",
      "Cost: 0.0 | Config ID: 148\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimiizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config f64af0 as new incumbent because there are no incumbents yet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 00:58:18,798 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:51036 remote=tcp://127.0.0.1:46313>: Stream is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_intensifier.py:594] Added config 0d93a9 and rejected config f64af0 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config b773ba and rejected config 0d93a9 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config eda38b and rejected config b773ba as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 99f2eb and rejected config eda38b as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 300 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 500 trials.\n",
      "[INFO][smbo.py:319] Finished 750 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 1050 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1250 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:319] Finished 1450 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1750 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1900 trials.\n",
      "[INFO][smbo.py:319] Finished 1950 trials.\n",
      "[INFO][smbo.py:319] Finished 2000 trials.\n",
      "[INFO][smbo.py:319] Finished 2000 trials.\n",
      "[INFO][smbo.py:319] Finished 2050 trials.\n",
      "[INFO][smbo.py:319] Finished 2050 trials.\n",
      "[INFO][smbo.py:319] Finished 2050 trials.\n",
      "[INFO][smbo.py:319] Finished 2050 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2150 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2300 trials.\n",
      "[INFO][smbo.py:319] Finished 2300 trials.\n",
      "[INFO][smbo.py:319] Finished 2300 trials.\n",
      "[INFO][smbo.py:319] Finished 2300 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2400 trials.\n",
      "[INFO][smbo.py:319] Finished 2450 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2650 trials.\n",
      "[INFO][smbo.py:319] Finished 2700 trials.\n",
      "[INFO][smbo.py:319] Finished 2700 trials.\n",
      "[INFO][smbo.py:319] Finished 2700 trials.\n",
      "[INFO][smbo.py:319] Finished 2750 trials.\n",
      "[INFO][smbo.py:319] Finished 2800 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -5.482200622558594\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 7196\n",
      "Parameters: {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'sqrt', 'max_samples': 0.9706978963446904, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 317}\n",
      "Cost: 0.0 | Config ID: 99\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimiizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config 5b1b2f as new incumbent because there are no incumbents yet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 01:59:12,536 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54042 remote=tcp://127.0.0.1:34333>: Stream is closed\n",
      "2024-09-22 01:59:12,537 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54058 remote=tcp://127.0.0.1:34333>: Stream is closed\n",
      "2024-09-22 01:59:12,538 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54070 remote=tcp://127.0.0.1:34333>: Stream is closed\n",
      "2024-09-22 01:59:12,539 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54094 remote=tcp://127.0.0.1:34333>: Stream is closed\n",
      "2024-09-22 01:59:12,540 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54052 remote=tcp://127.0.0.1:34333>: Stream is closed\n",
      "2024-09-22 01:59:12,540 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54086 remote=tcp://127.0.0.1:34333>: Stream is closed\n",
      "2024-09-22 01:59:12,542 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54104 remote=tcp://127.0.0.1:34333>: Stream is closed\n",
      "2024-09-22 01:59:12,543 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:54080 remote=tcp://127.0.0.1:34333>: Stream is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_intensifier.py:594] Added config 4411a2 and rejected config 5b1b2f as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config e3b1be and rejected config 4411a2 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config 33245a and rejected config e3b1be as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 88365f and rejected config 33245a as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 200 trials.\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 300 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 500 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 650 trials.\n",
      "[INFO][smbo.py:319] Finished 700 trials.\n",
      "[INFO][smbo.py:319] Finished 750 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -6.393721103668213\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 9216\n",
      "Parameters: {'criterion': 'log_loss', 'max_depth': 21, 'max_features': 'log2', 'max_samples': 0.984461385589925, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 776}\n",
      "Cost: 0.0 | Config ID: 61\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimiizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config ea1042 as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config ce7c03 and rejected config ea1042 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config e3b1be and rejected config ce7c03 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config 9a1c88 and rejected config e3b1be as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 0c783d and rejected config 9a1c88 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config 2cd073 and rejected config 0c783d as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 5f7ca1 and rejected config 2cd073 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 9740c6 and rejected config 5f7ca1 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 300 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 500 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 650 trials.\n",
      "[INFO][smbo.py:319] Finished 700 trials.\n",
      "[INFO][smbo.py:319] Finished 750 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -1.2524447441101074\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 9165\n",
      "Parameters: {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'sqrt', 'max_samples': 0.8807695097869216, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1492}\n",
      "Cost: 0.0 | Config ID: 100\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimiizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config 28d70f as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config 018ce3 and rejected config 28d70f as incumbent because it is not better than the incumbents on 1 instances:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 04:02:14,547 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:35172 remote=tcp://127.0.0.1:42249>: Stream is closed\n",
      "2024-09-22 04:02:14,548 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:35158 remote=tcp://127.0.0.1:42249>: Stream is closed\n",
      "2024-09-22 04:02:14,550 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:35148 remote=tcp://127.0.0.1:42249>: Stream is closed\n",
      "2024-09-22 04:02:14,550 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:35174 remote=tcp://127.0.0.1:42249>: Stream is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_intensifier.py:594] Added config f2f7c1 and rejected config 018ce3 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config cf0bbc and rejected config f2f7c1 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config a68901 and rejected config cf0bbc as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config a237ae and rejected config a68901 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config d61414 and rejected config a237ae as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 79a545 and rejected config d61414 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 140efc and rejected config 79a545 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 8918cc and rejected config 140efc as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 200 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config d71eee and rejected config 8918cc as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 300 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 500 trials.\n",
      "[INFO][smbo.py:319] Finished 750 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1050 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1150 trials.\n",
      "[INFO][smbo.py:319] Finished 1200 trials.\n",
      "[INFO][smbo.py:319] Finished 1250 trials.\n",
      "[INFO][smbo.py:319] Finished 1300 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:319] Finished 1400 trials.\n",
      "[INFO][smbo.py:319] Finished 1400 trials.\n",
      "[INFO][smbo.py:319] Finished 1400 trials.\n",
      "[INFO][smbo.py:319] Finished 1400 trials.\n",
      "[INFO][smbo.py:319] Finished 1450 trials.\n",
      "[INFO][smbo.py:319] Finished 1500 trials.\n",
      "[INFO][smbo.py:319] Finished 1600 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1700 trials.\n",
      "[INFO][smbo.py:319] Finished 1750 trials.\n",
      "[INFO][smbo.py:319] Finished 1750 trials.\n",
      "[INFO][smbo.py:319] Finished 1750 trials.\n",
      "[INFO][smbo.py:319] Finished 1750 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1950 trials.\n",
      "[INFO][smbo.py:319] Finished 1950 trials.\n",
      "[INFO][smbo.py:319] Finished 1950 trials.\n",
      "[INFO][smbo.py:319] Finished 1950 trials.\n",
      "[INFO][smbo.py:319] Finished 1950 trials.\n",
      "[INFO][smbo.py:319] Finished 1950 trials.\n",
      "[INFO][smbo.py:319] Finished 2000 trials.\n",
      "[INFO][smbo.py:319] Finished 2100 trials.\n",
      "[INFO][smbo.py:319] Finished 2150 trials.\n",
      "[INFO][smbo.py:319] Finished 2150 trials.\n",
      "[INFO][smbo.py:319] Finished 2150 trials.\n",
      "[INFO][smbo.py:319] Finished 2150 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2250 trials.\n",
      "[INFO][smbo.py:319] Finished 2250 trials.\n",
      "[INFO][smbo.py:319] Finished 2250 trials.\n",
      "[INFO][smbo.py:319] Finished 2250 trials.\n",
      "[INFO][smbo.py:319] Finished 2250 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2450 trials.\n",
      "[INFO][smbo.py:319] Finished 2500 trials.\n",
      "[INFO][smbo.py:319] Finished 2550 trials.\n",
      "[INFO][smbo.py:319] Finished 2600 trials.\n",
      "[INFO][smbo.py:319] Finished 2700 trials.\n",
      "[INFO][smbo.py:319] Finished 2700 trials.\n",
      "[INFO][smbo.py:319] Finished 2700 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -1.2172846794128418\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 7278\n",
      "Parameters: {'criterion': 'log_loss', 'max_depth': 21, 'max_features': 'sqrt', 'max_samples': 0.9430914127076302, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 201}\n",
      "Cost: 0.0 | Config ID: 137\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimiizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 05:00:41,317 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:33502 remote=tcp://127.0.0.1:46539>: Stream is closed\n",
      "2024-09-22 05:00:41,319 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:33460 remote=tcp://127.0.0.1:46539>: Stream is closed\n",
      "2024-09-22 05:00:41,319 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:33484 remote=tcp://127.0.0.1:46539>: Stream is closed\n",
      "2024-09-22 05:00:41,320 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:33508 remote=tcp://127.0.0.1:46539>: Stream is closed\n",
      "2024-09-22 05:00:41,322 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:33520 remote=tcp://127.0.0.1:46539>: Stream is closed\n",
      "2024-09-22 05:00:41,322 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:33468 remote=tcp://127.0.0.1:46539>: Stream is closed\n",
      "2024-09-22 05:00:41,322 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:33490 remote=tcp://127.0.0.1:46539>: Stream is closed\n",
      "2024-09-22 05:00:41,324 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:33532 remote=tcp://127.0.0.1:46539>: Stream is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_intensifier.py:515] Added config ac075f as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config 7e62eb and rejected config ac075f as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 052167 and rejected config 7e62eb as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 990a80 and rejected config 052167 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 05:03:17,595 - distributed.utils_perf - INFO - full garbage collection released 70.70 MiB from 15427 reference cycles (threshold: 9.54 MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_intensifier.py:594] Added config e3b1be and rejected config 990a80 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config a13393 and rejected config e3b1be as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config d1770e and rejected config a13393 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 200 trials.\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 300 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -13.340359687805176\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 9641\n",
      "Parameters: {'criterion': 'log_loss', 'max_depth': 19, 'max_features': 'sqrt', 'max_samples': 0.9508180480705797, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1275}\n",
      "Cost: 0.0 | Config ID: 84\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimiizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config fa0937 as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config 1eacdf and rejected config fa0937 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 95be80 and rejected config 1eacdf as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config e3b1be and rejected config 95be80 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 0666ce and rejected config e3b1be as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config c8664d and rejected config 0666ce as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 4240b4 and rejected config c8664d as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 5b693f and rejected config 4240b4 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 300 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 500 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 650 trials.\n",
      "[INFO][smbo.py:319] Finished 700 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -0.43663692474365234\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 9273\n",
      "Parameters: {'criterion': 'entropy', 'max_depth': 20, 'max_features': 'sqrt', 'max_samples': 0.9639616992832429, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 273}\n",
      "Cost: 0.0 | Config ID: 90\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimiizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 07:09:10,895 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "2024-09-22 07:09:10,897 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "2024-09-22 07:09:10,898 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "2024-09-22 07:09:10,900 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "2024-09-22 07:09:10,908 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "2024-09-22 07:09:10,909 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "2024-09-22 07:09:10,910 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "2024-09-22 07:09:10,913 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_intensifier.py:515] Added config 92cbc0 as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config 5b1b21 and rejected config 92cbc0 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config e3b1be and rejected config 5b1b21 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config ec7e76 and rejected config e3b1be as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 1b00b6 and rejected config ec7e76 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 300 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 500 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 650 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -5.192521810531616\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 9328\n",
      "Parameters: {'criterion': 'gini', 'max_depth': 21, 'max_features': 'None', 'max_samples': 0.9766012729733919, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 723}\n",
      "Cost: 0.0 | Config ID: 118\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimiizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 08:12:20,997 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:45994 remote=tcp://127.0.0.1:46539>: Stream is closed\n",
      "2024-09-22 08:12:20,999 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:45926 remote=tcp://127.0.0.1:46539>: Stream is closed\n",
      "2024-09-22 08:12:20,999 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:45964 remote=tcp://127.0.0.1:46539>: Stream is closed\n",
      "2024-09-22 08:12:21,000 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:45980 remote=tcp://127.0.0.1:46539>: Stream is closed\n",
      "2024-09-22 08:12:21,001 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46012 remote=tcp://127.0.0.1:46539>: Stream is closed\n",
      "2024-09-22 08:12:21,002 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46004 remote=tcp://127.0.0.1:46539>: Stream is closed\n",
      "2024-09-22 08:12:21,003 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:46016 remote=tcp://127.0.0.1:46539>: Stream is closed\n",
      "2024-09-22 08:12:21,004 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:45952 remote=tcp://127.0.0.1:46539>: Stream is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_intensifier.py:515] Added config 191c83 as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config e3b1be and rejected config 191c83 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 0ea789 and rejected config e3b1be as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 69dc84 and rejected config 0ea789 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config 053fb2 and rejected config 69dc84 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config c80f62 and rejected config 053fb2 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 70ab19 and rejected config c80f62 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config b50c93 and rejected config 70ab19 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 6bec3c and rejected config b50c93 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 4366d5 and rejected config 6bec3c as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config c20e75 and rejected config 4366d5 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 200 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config ae6e1a and rejected config c20e75 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 6e6f55 and rejected config ae6e1a as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config a1b06e and rejected config 6e6f55 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 2346ef and rejected config a1b06e as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config 61daac and rejected config 2346ef as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 70da97 and rejected config 61daac as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 300 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config 9dbdf4 and rejected config 70da97 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config d5286b and rejected config 9dbdf4 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 83cec4 and rejected config d5286b as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config debc4b and rejected config 83cec4 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 650 trials.\n",
      "[INFO][smbo.py:319] Finished 700 trials.\n",
      "[INFO][smbo.py:319] Finished 700 trials.\n",
      "[INFO][smbo.py:319] Finished 750 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config dd49a7 and rejected config debc4b as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 1050 trials.\n",
      "[INFO][smbo.py:319] Finished 1050 trials.\n",
      "[INFO][smbo.py:319] Finished 1050 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config 2aa6e0 and rejected config dd49a7 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1150 trials.\n",
      "[INFO][smbo.py:319] Finished 1150 trials.\n",
      "[INFO][smbo.py:319] Finished 1150 trials.\n",
      "[INFO][smbo.py:319] Finished 1150 trials.\n",
      "[INFO][smbo.py:319] Finished 1150 trials.\n",
      "[INFO][smbo.py:319] Finished 1200 trials.\n",
      "[INFO][smbo.py:319] Finished 1200 trials.\n",
      "[INFO][smbo.py:319] Finished 1200 trials.\n",
      "[INFO][smbo.py:319] Finished 1200 trials.\n",
      "[INFO][smbo.py:319] Finished 1250 trials.\n",
      "[INFO][smbo.py:319] Finished 1300 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:319] Finished 1450 trials.\n",
      "[INFO][smbo.py:319] Finished 1600 trials.\n",
      "[INFO][smbo.py:319] Finished 1750 trials.\n",
      "[INFO][smbo.py:319] Finished 1750 trials.\n",
      "[INFO][smbo.py:319] Finished 1800 trials.\n",
      "[INFO][smbo.py:319] Finished 1850 trials.\n",
      "[INFO][smbo.py:319] Finished 1900 trials.\n",
      "[INFO][smbo.py:319] Finished 2000 trials.\n",
      "[INFO][smbo.py:319] Finished 2000 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2200 trials.\n",
      "[INFO][smbo.py:319] Finished 2250 trials.\n",
      "[INFO][smbo.py:319] Finished 2300 trials.\n",
      "[INFO][smbo.py:319] Finished 2350 trials.\n",
      "[INFO][smbo.py:319] Finished 2400 trials.\n",
      "[INFO][smbo.py:319] Finished 2400 trials.\n",
      "[INFO][smbo.py:319] Finished 2500 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -1.7475075721740723\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 7460\n",
      "Parameters: {'criterion': 'gini', 'max_depth': 21, 'max_features': 'None', 'max_samples': 0.9882011939644544, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 816}\n",
      "Cost: 0.013399999999999967 | Config ID: 815\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimiizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config 13de14 as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config 9295bf and rejected config 13de14 as incumbent because it is not better than the incumbents on 1 instances:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 09:15:05,679 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:40678 remote=tcp://127.0.0.1:37757>: Stream is closed\n",
      "2024-09-22 09:15:05,682 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:40664 remote=tcp://127.0.0.1:37757>: Stream is closed\n",
      "2024-09-22 09:15:05,682 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:40644 remote=tcp://127.0.0.1:37757>: Stream is closed\n",
      "2024-09-22 09:15:05,684 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:40650 remote=tcp://127.0.0.1:37757>: Stream is closed\n",
      "2024-09-22 09:15:05,684 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:40708 remote=tcp://127.0.0.1:37757>: Stream is closed\n",
      "2024-09-22 09:15:05,685 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:40648 remote=tcp://127.0.0.1:37757>: Stream is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_intensifier.py:594] Added config e3b1be and rejected config 9295bf as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config e780d6 and rejected config e3b1be as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config fc36c2 and rejected config e780d6 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config 30128a and rejected config fc36c2 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 200 trials.\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -2.1071178913116455\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 9726\n",
      "Parameters: {'criterion': 'log_loss', 'max_depth': 16, 'max_features': 'log2', 'max_samples': 0.8111828376617547, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 1340}\n",
      "Cost: 0.0 | Config ID: 81\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimiizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config 159fb1 as new incumbent because there are no incumbents yet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 10:24:10,552 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50464 remote=tcp://127.0.0.1:36997>: Stream is closed\n",
      "2024-09-22 10:24:10,554 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50424 remote=tcp://127.0.0.1:36997>: Stream is closed\n",
      "2024-09-22 10:24:10,554 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50418 remote=tcp://127.0.0.1:36997>: Stream is closed\n",
      "2024-09-22 10:24:10,559 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50454 remote=tcp://127.0.0.1:36997>: Stream is closed\n",
      "2024-09-22 10:24:10,559 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:50414 remote=tcp://127.0.0.1:36997>: Stream is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_intensifier.py:594] Added config e3b1be and rejected config 159fb1 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config 869ad1 and rejected config e3b1be as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config c47c70 and rejected config 869ad1 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config d39f5a and rejected config c47c70 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config ec1379 and rejected config d39f5a as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config c1b425 and rejected config ec1379 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 10e4e0 and rejected config c1b425 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 1adbb2 and rejected config 10e4e0 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 0eb0c1 and rejected config 1adbb2 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config dca48a and rejected config 0eb0c1 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 500 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config 8b1eff and rejected config dca48a as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 650 trials.\n",
      "[INFO][smbo.py:319] Finished 700 trials.\n",
      "[INFO][smbo.py:319] Finished 750 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 850 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -2.8857314586639404\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 9031\n",
      "Parameters: {'criterion': 'gini', 'max_depth': 21, 'max_features': 'None', 'max_samples': 0.9888965344844416, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 708}\n",
      "Cost: 0.0010000000000000009 | Config ID: 439\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimiizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 11:24:31,371 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "2024-09-22 11:24:31,372 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "2024-09-22 11:24:31,507 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "2024-09-22 11:24:31,510 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "2024-09-22 11:24:31,513 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "2024-09-22 11:24:31,515 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "2024-09-22 11:24:31,517 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "2024-09-22 11:24:31,519 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
      "2024-09-22 11:24:31,520 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_intensifier.py:515] Added config e04e5a as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config e3d7df and rejected config e04e5a as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config ec275e and rejected config e3d7df as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 0a69c8 and rejected config ec275e as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 200 trials.\n",
      "[INFO][smbo.py:319] Finished 300 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 500 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -4.926150321960449\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 9375\n",
      "Parameters: {'criterion': 'entropy', 'max_depth': 18, 'max_features': 'sqrt', 'max_samples': 0.965042981366695, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 138}\n",
      "Cost: 0.0 | Config ID: 83\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimiizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config f43638 as new incumbent because there are no incumbents yet.\n",
      "[INFO][abstract_intensifier.py:594] Added config 7d0223 and rejected config f43638 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config b6e893 and rejected config 7d0223 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 9040c7 and rejected config b6e893 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config e3b1be and rejected config 9040c7 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config 1b2a4b and rejected config e3b1be as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 2a1918 and rejected config 1b2a4b as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config e9fcd3 and rejected config 2a1918 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config d6166a and rejected config e9fcd3 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config aacfe2 and rejected config d6166a as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 200 trials.\n",
      "[INFO][smbo.py:319] Finished 300 trials.\n",
      "[INFO][smbo.py:319] Finished 300 trials.\n",
      "[INFO][smbo.py:319] Finished 300 trials.\n",
      "[INFO][smbo.py:319] Finished 300 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 500 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 700 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 850 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1000 trials.\n",
      "[INFO][smbo.py:319] Finished 1050 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1150 trials.\n",
      "[INFO][smbo.py:319] Finished 1300 trials.\n",
      "[INFO][smbo.py:319] Finished 1400 trials.\n",
      "[INFO][smbo.py:319] Finished 1450 trials.\n",
      "[INFO][smbo.py:319] Finished 1500 trials.\n",
      "[INFO][smbo.py:319] Finished 1550 trials.\n",
      "[INFO][smbo.py:319] Finished 1600 trials.\n",
      "[INFO][smbo.py:319] Finished 1650 trials.\n",
      "[INFO][smbo.py:319] Finished 1700 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -0.48824405670166016\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 8273\n",
      "Parameters: {'criterion': 'entropy', 'max_depth': 18, 'max_features': 'log2', 'max_samples': 0.9836780040383323, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 385}\n",
      "Cost: 0.0 | Config ID: 129\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimiizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][abstract_intensifier.py:515] Added config 32655b as new incumbent because there are no incumbents yet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 13:30:34,756 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44906 remote=tcp://127.0.0.1:46235>: Stream is closed\n",
      "2024-09-22 13:30:34,757 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44900 remote=tcp://127.0.0.1:46235>: Stream is closed\n",
      "2024-09-22 13:30:34,757 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44888 remote=tcp://127.0.0.1:46235>: Stream is closed\n",
      "2024-09-22 13:30:34,759 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44910 remote=tcp://127.0.0.1:46235>: Stream is closed\n",
      "2024-09-22 13:30:34,760 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44924 remote=tcp://127.0.0.1:46235>: Stream is closed\n",
      "2024-09-22 13:30:34,761 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 452, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/utils_comm.py\", line 431, in retry\n",
      "    return await coro()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:44932 remote=tcp://127.0.0.1:46235>: Stream is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][smbo.py:319] Finished 50 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config d83666 and rejected config 32655b as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config 3dc15a and rejected config d83666 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config c8c7d6 and rejected config 3dc15a as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][abstract_intensifier.py:594] Added config a32ff8 and rejected config c8c7d6 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][abstract_intensifier.py:594] Added config ca9d08 and rejected config a32ff8 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "[INFO][smbo.py:319] Finished 200 trials.\n",
      "[INFO][smbo.py:319] Finished 300 trials.\n",
      "[INFO][smbo.py:319] Finished 350 trials.\n",
      "[INFO][smbo.py:319] Finished 400 trials.\n",
      "[INFO][smbo.py:319] Finished 450 trials.\n",
      "[INFO][smbo.py:319] Finished 500 trials.\n",
      "[INFO][smbo.py:319] Finished 550 trials.\n",
      "[INFO][smbo.py:319] Finished 600 trials.\n",
      "[INFO][smbo.py:319] Finished 650 trials.\n",
      "[INFO][smbo.py:319] Finished 700 trials.\n",
      "[INFO][smbo.py:319] Finished 750 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 800 trials.\n",
      "[INFO][smbo.py:319] Finished 850 trials.\n",
      "[INFO][smbo.py:319] Finished 900 trials.\n",
      "[INFO][smbo.py:319] Finished 950 trials.\n",
      "[INFO][smbo.py:319] Finished 1050 trials.\n",
      "[INFO][smbo.py:319] Finished 1100 trials.\n",
      "[INFO][smbo.py:319] Finished 1200 trials.\n",
      "[INFO][smbo.py:319] Finished 1250 trials.\n",
      "[INFO][smbo.py:319] Finished 1300 trials.\n",
      "[INFO][smbo.py:319] Finished 1350 trials.\n",
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -4.3820085525512695\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 8598\n",
      "Parameters: {'criterion': 'log_loss', 'max_depth': 21, 'max_features': 'log2', 'max_samples': 0.989612251370181, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 214}\n",
      "Cost: 0.027800000000000047 | Config ID: 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 14:50:38,268 - distributed.scheduler - INFO - Remove client Client-f44b848d-7907-11ef-8927-246e9624e1b0\n",
      "2024-09-22 14:50:38,270 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37522; closing.\n",
      "2024-09-22 14:50:38,273 - distributed.scheduler - INFO - Remove client Client-f44b848d-7907-11ef-8927-246e9624e1b0\n",
      "2024-09-22 14:50:38,275 - distributed.scheduler - INFO - Close client connection: Client-f44b848d-7907-11ef-8927-246e9624e1b0\n",
      "2024-09-22 14:50:38,279 - distributed.scheduler - INFO - Retire worker addresses (0, 1, 2, 3, 4, 5, 6, 7)\n",
      "2024-09-22 14:50:38,282 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39547'. Reason: nanny-close\n",
      "2024-09-22 14:50:38,286 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-09-22 14:50:38,287 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33317'. Reason: nanny-close\n",
      "2024-09-22 14:50:38,290 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-09-22 14:50:38,291 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42081'. Reason: nanny-close\n",
      "2024-09-22 14:50:38,293 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-09-22 14:50:38,295 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38639'. Reason: nanny-close\n",
      "2024-09-22 14:50:38,298 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-09-22 14:50:38,299 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35197'. Reason: nanny-close\n",
      "2024-09-22 14:50:38,301 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-09-22 14:50:38,303 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39523'. Reason: nanny-close\n",
      "2024-09-22 14:50:38,306 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-09-22 14:50:38,307 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43853'. Reason: nanny-close\n",
      "2024-09-22 14:50:38,310 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-09-22 14:50:38,313 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38731'. Reason: nanny-close\n",
      "2024-09-22 14:50:38,316 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close\n",
      "2024-09-22 14:50:38,359 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37454; closing.\n",
      "2024-09-22 14:50:38,361 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37440; closing.\n",
      "2024-09-22 14:50:38,363 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37466; closing.\n",
      "2024-09-22 14:50:38,364 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37472; closing.\n",
      "2024-09-22 14:50:38,365 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37484; closing.\n",
      "2024-09-22 14:50:38,368 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37492; closing.\n",
      "2024-09-22 14:50:38,370 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37494; closing.\n",
      "2024-09-22 14:50:38,374 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37561', name: 0, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1727031038.3741255')\n",
      "2024-09-22 14:50:38,376 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42109', name: 1, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1727031038.3766503')\n",
      "2024-09-22 14:50:38,379 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40649', name: 2, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1727031038.3797972')\n",
      "2024-09-22 14:50:38,381 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40577', name: 3, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1727031038.3815722')\n",
      "2024-09-22 14:50:38,384 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38899', name: 4, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1727031038.3841321')\n",
      "2024-09-22 14:50:38,386 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41981', name: 5, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1727031038.3866909')\n",
      "2024-09-22 14:50:38,389 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40685', name: 6, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1727031038.3892808')\n",
      "2024-09-22 14:50:38,391 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37510; closing.\n",
      "2024-09-22 14:50:38,396 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41661', name: 7, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1727031038.396016')\n",
      "2024-09-22 14:50:38,397 - distributed.scheduler - INFO - Lost all workers\n",
      "2024-09-22 14:50:38,435 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:41903 remote=tcp://127.0.0.1:37510>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/batched.py\", line 115, in _background_send\n",
      "    nbytes = yield coro\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/tornado/gen.py\", line 767, in run\n",
      "    value = future.result()\n",
      "  File \"/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 262, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "2024-09-22 14:50:38,676 - distributed.scheduler - INFO - Scheduler closing due to unknown reason...\n",
      "2024-09-22 14:50:38,681 - distributed.scheduler - INFO - Scheduler closing all comms\n"
     ]
    }
   ],
   "source": [
    "params_dict_RF = {}\n",
    "for i in range(len(train_x_list)):\n",
    "    train_x = train_x_list[i]\n",
    "    train_y = train_y_list[i]\n",
    "    class RFWrapper(BaseEstimator):\n",
    "        def __init__(self, n_estimators=100, max_depth=2, random_state=317, min_samples_split=2, min_samples_leaf=1, max_features=None, criterion=\"gini\", max_samples = 0.5):\n",
    "            self.n_estimators = n_estimators\n",
    "            self.max_depth = max_depth\n",
    "            self.random_state = random_state\n",
    "            self.min_samples_split = min_samples_split\n",
    "            self.min_samples_leaf = min_samples_leaf\n",
    "            self.max_features = max_features   \n",
    "            self.criterion = \"gini\"\n",
    "            self.max_samples = max_samples\n",
    "            self.model = RandomForestClassifier(n_estimators=self.n_estimators, max_depth=self.max_depth, random_state=self.random_state, min_samples_split=self.min_samples_split, min_samples_leaf=self.min_samples_leaf, criterion=self.criterion, max_features=self.max_features, max_samples=self.max_samples)\n",
    "\n",
    "        @property\n",
    "        def configspace(self) -> ConfigurationSpace:\n",
    "            cs = ConfigurationSpace()\n",
    "            n_estimators = Integer(\"n_estimators\", (100, 1500), default=100)\n",
    "            max_depth = Integer(\"max_depth\", (2,21), default=2)\n",
    "            min_samples_split = Integer(\"min_samples_split\", (2, 20), default=2)\n",
    "            min_samples_leaf = Integer(\"min_samples_leaf\", (1, 20), default=1)\n",
    "            criterion = Categorical(\"criterion\", [\"gini\", \"entropy\", \"log_loss\"], default=\"gini\")\n",
    "            max_features = Categorical(\"max_features\", [\"sqrt\", \"log2\", \"None\"], default=\"None\")\n",
    "            max_samples = Float(\"max_samples\", (0.1, 0.99), log=True)\n",
    "            cs.add_hyperparameters([n_estimators, max_depth, min_samples_split, min_samples_leaf, criterion, max_features, max_samples])\n",
    "            return cs\n",
    "        \n",
    "        def fit(self, config: Configuration, seed: int = 0, budget: int = 250) -> float: \n",
    "            config = dict(config)  \n",
    "            if config['max_features'] == 'None':\n",
    "                config['max_features'] = None\n",
    "            self.model.set_params(**config)\n",
    "            X = train_x\n",
    "            y = train_y\n",
    "            self.model.fit(X, y)\n",
    "            preds = self.model.predict(X)\n",
    "            scores = accuracy_score(y, preds)\n",
    "\n",
    "            return 1 - scores\n",
    "\n",
    "    # @timeout(90)\n",
    "    def main():\n",
    "        RF = RFWrapper()\n",
    "\n",
    "        facades: list[AbstractFacade] = []\n",
    "        for intensifier_object in [Hyperband]:\n",
    "\n",
    "            scenario = Scenario(\n",
    "                RF.configspace,\n",
    "                walltime_limit=3600,\n",
    "                output_directory=Path(\"smac_hyperband_output_budget_1hr_RF_337/\" + dataset_names[i]),\n",
    "                n_trials=10000,\n",
    "                min_budget=100,\n",
    "                max_budget=1000,\n",
    "                n_workers=8,\n",
    "\n",
    "            )\n",
    "\n",
    "            initial_design = MFFacade.get_initial_design(scenario, n_configs=5)\n",
    "            intensifier = intensifier_object(scenario, incumbent_selection=\"highest_budget\")\n",
    "\n",
    "            smac = MFFacade(\n",
    "                scenario,\n",
    "                RF.fit,\n",
    "                initial_design=initial_design,\n",
    "                intensifier=intensifier,\n",
    "                overwrite=True,\n",
    "            )\n",
    "\n",
    "            print(\"optimiizing\")\n",
    "            # print(type(smac), \"|\", smac)\n",
    "            incumbent = smac.optimize()\n",
    "            best_params = incumbent.get_dictionary()\n",
    "            params_dict_RF[dataset_names[i]] = best_params\n",
    "\n",
    "            incumbent_cost = smac.runhistory.get_cost(incumbent)\n",
    "            incumbent_run_id = incumbent.config_id\n",
    "\n",
    "            print(f\"Parameters: {best_params}\")\n",
    "            print(f\"Cost: {incumbent_cost} | Config ID: {incumbent_run_id}\")\n",
    "\n",
    "            default_cost = smac.validate(RF.configspace.get_default_configuration())\n",
    "            # print(f\"Default cost ({intensifier.__class__.__name__}): {default_cost}\")\n",
    "            incumbent_cost = smac.validate(incumbent)\n",
    "            # print(f\"Incumbent cost ({intensifier.__class__.__name__}): {incumbent_cost}\")\n",
    "\n",
    "            facades.append(smac)\n",
    "        #     for arrt in dir(smac):\n",
    "        #         if not arrt.startswith(\"_\"):\n",
    "        #             print(arrt, getattr(smac, arrt))\n",
    "\n",
    "        # print(\"facades:\", facades)\n",
    "\n",
    "\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        # with open('smac_results_2h.txt', \"w\") as f:\n",
    "        #     pass\n",
    "        # profiler = LineProfiler()\n",
    "        # profiler.add_function(main)\n",
    "        # profiler.enable()\n",
    "\n",
    "        main()\n",
    "\n",
    "        # profiler.disable()\n",
    "        # profiler.print_stats()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of runhistory_data_CNN: 1077\n",
      "CNN min 1:\n",
      "Config ID: 521, Cost: 0.0, Parameters: {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'None', 'max_samples': 0.9812660700637297, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 320}\n",
      "\n",
      "{'albert': {'criterion': 'gini', 'max_depth': 17, 'max_features': 'None', 'max_samples': 0.9727926495978603, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 859}, 'compas-two-years': {'criterion': 'gini', 'max_depth': 18, 'max_features': 'log2', 'max_samples': 0.9723218124088577, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 224}, 'covertype': {'criterion': 'gini', 'max_depth': 19, 'max_features': 'None', 'max_samples': 0.9875527991780877, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 696}, 'default-of-credit-card-clients': {'criterion': 'gini', 'max_depth': 21, 'max_features': 'None', 'max_samples': 0.9858398960835011, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 703}, 'electricity': {'criterion': 'log_loss', 'max_depth': 18, 'max_features': 'None', 'max_samples': 0.8313278444181132, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1117}, 'eye_movements': {'criterion': 'gini', 'max_depth': 17, 'max_features': 'log2', 'max_samples': 0.908385857344539, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 237}, 'road-safety': {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'None', 'max_samples': 0.9812660700637297, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 320}}\n"
     ]
    }
   ],
   "source": [
    "# params_dict_RF_1hr = {}\n",
    "name = \"road-safety\"\n",
    "runhistory_path = \"smac_hyperband_output_budget_1hr_RF_334/road-safety/80369a6b8358032cab31c23967a470da/0/runhistory.json\"\n",
    "\n",
    "with open(runhistory_path, \"r\") as file:\n",
    "    runhistory_data_CNN = json.load(file)\n",
    "\n",
    "print(\"Length of runhistory_data_CNN:\", len(runhistory_data_CNN[\"data\"]))\n",
    "\n",
    "configs_costs_CNN = []\n",
    "for entry in runhistory_data_CNN[\"data\"]:\n",
    "    # print(entry)\n",
    "    config_id = entry[0]  \n",
    "    cost = entry[4]  \n",
    "    configs_costs_CNN.append((entry[0], entry[4]))\n",
    "    configs_costs_CNN = list(set(configs_costs_CNN))\n",
    "\n",
    "min_cost_config_CNN = sorted(configs_costs_CNN, key=lambda x: x[1])[0]\n",
    "print(\"CNN min 1:\")\n",
    "config_id, cost = min_cost_config_CNN\n",
    "params = runhistory_data_CNN[\"configs\"][str(config_id)]\n",
    "print(f\"Config ID: {config_id}, Cost: {cost}, Parameters: {params}\\n\")\n",
    "params_dict_RF_1hr[name] = params\n",
    "file.close()\n",
    "print(params_dict_RF_1hr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: credit, Best Parameters: {'criterion': 'entropy', 'max_depth': 20, 'max_features': 'sqrt', 'max_samples': 0.9691083523958117, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 252}\n",
      "Dataset: electricity, Best Parameters: {'criterion': 'gini', 'max_depth': 20, 'max_features': 'log2', 'max_samples': 0.9647413210898548, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 108}\n",
      "Dataset: covertype, Best Parameters: {'criterion': 'gini', 'max_depth': 21, 'max_features': 'sqrt', 'max_samples': 0.9847607906550341, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 302}\n",
      "Dataset: pol, Best Parameters: {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'sqrt', 'max_samples': 0.9706978963446904, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 317}\n",
      "Dataset: house_16H, Best Parameters: {'criterion': 'log_loss', 'max_depth': 21, 'max_features': 'log2', 'max_samples': 0.984461385589925, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 776}\n",
      "Dataset: MagicTelescope, Best Parameters: {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'sqrt', 'max_samples': 0.8807695097869216, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1492}\n",
      "Dataset: bank-marketing, Best Parameters: {'criterion': 'log_loss', 'max_depth': 21, 'max_features': 'sqrt', 'max_samples': 0.9430914127076302, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 201}\n",
      "Dataset: MiniBooNE, Best Parameters: {'criterion': 'log_loss', 'max_depth': 19, 'max_features': 'sqrt', 'max_samples': 0.9508180480705797, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1275}\n",
      "Dataset: Higgs, Best Parameters: {'criterion': 'entropy', 'max_depth': 20, 'max_features': 'sqrt', 'max_samples': 0.9639616992832429, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 273}\n",
      "Dataset: eye_movements, Best Parameters: {'criterion': 'gini', 'max_depth': 21, 'max_features': 'None', 'max_samples': 0.9766012729733919, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 723}\n",
      "Dataset: Diabetes130US, Best Parameters: {'criterion': 'gini', 'max_depth': 21, 'max_features': 'None', 'max_samples': 0.9882011939644544, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 816}\n",
      "Dataset: jannis, Best Parameters: {'criterion': 'log_loss', 'max_depth': 16, 'max_features': 'log2', 'max_samples': 0.8111828376617547, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 1340}\n",
      "Dataset: default-of-credit-card-clients, Best Parameters: {'criterion': 'gini', 'max_depth': 21, 'max_features': 'None', 'max_samples': 0.9888965344844416, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 708}\n",
      "Dataset: Bioresponse, Best Parameters: {'criterion': 'entropy', 'max_depth': 18, 'max_features': 'sqrt', 'max_samples': 0.965042981366695, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 138}\n",
      "Dataset: california, Best Parameters: {'criterion': 'entropy', 'max_depth': 18, 'max_features': 'log2', 'max_samples': 0.9836780040383323, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 385}\n",
      "Dataset: heloc, Best Parameters: {'criterion': 'log_loss', 'max_depth': 21, 'max_features': 'log2', 'max_samples': 0.989612251370181, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 214}\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, params in params_dict_RF.items():\n",
    "    print(f\"Dataset: {dataset_name}, Best Parameters: {params}\")\n",
    "    # print(f\"Best Parameters: {params}\")\n",
    "with open(\"SmacResults/337/RF_params_1hr.json\", 'w') as f:\n",
    "    json.dump(params_dict_RF, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabWrapper(BaseEstimator):\n",
    "    def __init__(self, n_d=64, n_a=64, n_steps=5, gamma=1.3, n_independent=2, n_shared=2, seed=317, optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=1e-2), scheduler_params={\"step_size\":50, \"gamma\":0.9}, scheduler_fn=torch.optim.lr_scheduler.StepLR, mask_type='entmax', verbose=0):\n",
    "        self.n_d = n_d\n",
    "        self.n_a = n_a\n",
    "        self.n_steps = n_steps\n",
    "        self.gamma = gamma\n",
    "        self.n_independent = n_independent\n",
    "        self.n_shared = n_shared\n",
    "        self.seed = seed\n",
    "        self.optimizer_fn = optimizer_fn\n",
    "        self.optimizer_params = optimizer_params\n",
    "        self.scheduler_params = scheduler_params\n",
    "        self.scheduler_fn = scheduler_fn\n",
    "        self.mask_type = mask_type\n",
    "        self.model = TabNetClassifier(n_d=self.n_d, n_a=self.n_a, n_steps=self.n_steps, gamma=self.gamma, n_independent=self.n_independent, n_shared=self.n_shared, seed=self.seed, optimizer_fn=self.optimizer_fn, optimizer_params=self.optimizer_params, scheduler_params=self.scheduler_params, scheduler_fn=self.scheduler_fn, mask_type=self.mask_type)\n",
    "\n",
    "    @property\n",
    "    def configspace(self) -> ConfigurationSpace:\n",
    "        cs = ConfigurationSpace()\n",
    "        n_d = Integer(\"n_d\", (4, 256), default=64)\n",
    "        n_a = Integer(\"n_a\", (4, 256), default=64)\n",
    "        # n_steps = Integer(\"n_steps\", (3, 10), default=5)\n",
    "        # gamma = Float(\"gamma\", (0.9, 2.0), default=1.3)\n",
    "        # n_independent = Integer(\"n_independent\", (1, 10), default=2)\n",
    "        # n_shared = Integer(\"n_shared\", (1, 10), default=2)\n",
    "        # seed = Integer(\"seed\", (0, 1000), default=317)\n",
    "        # optimizer_fn = Categorical(\"optimizer_fn\", [torch.optim.Adam, torch.optim.AdamW], default=torch.optim.Adam)\n",
    "        # scheduler_fn = Categorical(\"scheduler_fn\", [torch.optim.lr_scheduler.StepLR, torch.optim.lr_scheduler.MultiStepLR], default=torch.optim.lr_scheduler.StepLR)\n",
    "        # mask_type = Categorical(\"mask_type\", ['sparsemax', 'entmax'], default='entmax')\n",
    "        cs.add_hyperparameters([n_d, n_a])\n",
    "        # cs.add_hyperparameters([n_d, n_a, n_steps, gamma, n_independent, n_shared, seed, optimizer_fn, scheduler_fn, mask_type])\n",
    "        return cs\n",
    "\n",
    "    def fit(self, config: Configuration, seed: int = 0, budget: int = 250) -> float:\n",
    "        config = dict(config)\n",
    "        self.model.set_params(**config)\n",
    "        X = train_x\n",
    "        y = train_y\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.model.fit(X_train, y_train, eval_set=[(X_val, y_val)], patience=50)\n",
    "        preds = self.model.predict(X_val)\n",
    "        score = accuracy_score(y_val, preds)\n",
    "        return 1 - score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeout(900)\n",
    "def main():\n",
    "    Tab = TabWrapper()\n",
    "\n",
    "    facades: list[AbstractFacade] = []\n",
    "    for intensifier_object in [Hyperband]:\n",
    "\n",
    "        scenario = Scenario(\n",
    "            Tab.configspace,\n",
    "            walltime_limit=600,\n",
    "            output_directory=Path(\"smac_hyperband_output_budget_10mins_Tab\"),\n",
    "            n_trials=10000,\n",
    "            min_budget=100,\n",
    "            max_budget=1000,\n",
    "            n_workers=8,\n",
    "\n",
    "        )\n",
    "\n",
    "        initial_design = MFFacade.get_initial_design(scenario, n_configs=5)\n",
    "        intensifier = intensifier_object(scenario, incumbent_selection=\"highest_budget\")\n",
    "\n",
    "        smac = MFFacade(\n",
    "            scenario,\n",
    "            Tab.fit,\n",
    "            initial_design=initial_design,\n",
    "            intensifier=intensifier,\n",
    "            overwrite=True,\n",
    "        )\n",
    "\n",
    "        print(\"optimiizing\")\n",
    "        print(type(smac), \"|\", smac)\n",
    "        incumbent = smac.optimize()\n",
    "        print(\"incumbent:\", incumbent)\n",
    "        default_cost = smac.validate(Tab.configspace.get_default_configuration())\n",
    "        print(f\"Default cost ({intensifier.__class__.__name__}): {default_cost}\")\n",
    "        incumbent_cost = smac.validate(incumbent)\n",
    "        print(f\"Incumbent cost ({intensifier.__class__.__name__}): {incumbent_cost}\")\n",
    "\n",
    "        facades.append(smac)\n",
    "        for arrt in dir(smac):\n",
    "            if not arrt.startswith(\"_\"):\n",
    "                print(arrt, getattr(smac, arrt))\n",
    "\n",
    "    print(\"facades:\", facades)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # with open('smac_results_2h.txt', \"w\") as f:\n",
    "    #     pass\n",
    "    profiler = LineProfiler()\n",
    "    profiler.add_function(main)\n",
    "    profiler.enable()\n",
    "\n",
    "    main()\n",
    "\n",
    "    profiler.disable()\n",
    "    profiler.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.84879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "params_dict_Tab = {}\n",
    "for i in range(len(train_x_list)):\n",
    "    train_x = train_x_list[i]\n",
    "    train_y = train_y_list[i]\n",
    "    class TabWrapper(BaseEstimator):\n",
    "        def __init__(self, n_d=8, n_a=8, n_steps=5, gamma=1.3, n_independent=2, n_shared=2, seed=317, optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=1e-2), mask_type='entmax', verbose=0):\n",
    "            self.n_d = n_d\n",
    "            self.n_a = n_a\n",
    "            self.n_steps = n_steps\n",
    "            self.gamma = gamma\n",
    "            self.n_independent = n_independent\n",
    "            self.n_shared = n_shared\n",
    "            self.seed = seed\n",
    "            self.optimizer_fn = optimizer_fn\n",
    "            self.optimizer_params = optimizer_params\n",
    "            self.mask_type = mask_type\n",
    "            self.verbose = 0\n",
    "            self.model = TabNetClassifier(n_d=self.n_d, n_a=self.n_a, n_steps=self.n_steps, gamma=self.gamma, n_independent=self.n_independent, n_shared=self.n_shared, seed=self.seed, optimizer_fn=self.optimizer_fn, optimizer_params=self.optimizer_params, mask_type=self.mask_type, verbose=self.verbose)\n",
    "\n",
    "        @property\n",
    "        def configspace(self) -> ConfigurationSpace:\n",
    "            cs = ConfigurationSpace()\n",
    "            n_d = Integer(\"n_d\", (4, 128), default=8)\n",
    "            n_a = Integer(\"n_a\", (4, 128), default=8)\n",
    "            n_steps = Integer(\"n_steps\", (3, 5), default=5)\n",
    "            gamma = Float(\"gamma\", (1, 2.0), default=1.3)\n",
    "            n_independent = Integer(\"n_independent\", (1, 10), default=2)\n",
    "            n_shared = Integer(\"n_shared\", (1, 10), default=2)\n",
    "            optimizer_fn = Categorical(\"optimizer_fn\", [torch.optim.Adam, torch.optim.AdamW], default=torch.optim.Adam)\n",
    "            # mask_type = Categorical(\"mask_type\", ['sparsemax', 'entmax'], default='entmax')\n",
    "            # seed = Integer(\"seed\", (317), default=317)\n",
    "            verbose = Categorical(\"verbose\", [0], default=0)\n",
    "            cs.add_hyperparameters([n_d, n_a, verbose])\n",
    "            # cs.add_hyperparameters([n_d, n_a, n_steps, gamma, n_independent, n_shared, seed, optimizer_fn, scheduler_fn, mask_type])\n",
    "            return cs\n",
    "\n",
    "        def fit(self, config: Configuration, seed: int = 0, budget: int = 250) -> float:\n",
    "            # config = dict(config)\n",
    "            # self.model.set_params(**config)\n",
    "            self.model = TabNetClassifier(n_d=config[\"n_d\"], n_a=config[\"n_a\"], verbose=self.verbose)\n",
    "            X = train_x\n",
    "            y = train_y\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            self.model.fit(X_train, y_train, eval_set=[(X_val, y_val)], patience=10)\n",
    "            preds = self.model.predict(X_val)\n",
    "            score = accuracy_score(y_val, preds)\n",
    "            return 1 - score    \n",
    "\n",
    "    @timeout(2100)\n",
    "    def main():\n",
    "        start_time = time.time()\n",
    "        print(\"Here 1\")\n",
    "        Tab = TabWrapper()\n",
    "\n",
    "        facades: list[AbstractFacade] = []\n",
    "        for intensifier_object in [Hyperband]:\n",
    "\n",
    "            scenario = Scenario(\n",
    "                Tab.configspace,\n",
    "                walltime_limit=1800,\n",
    "                output_directory=Path(\"smac_hyperband_output_budget_30mins_Tab/\" + dataset_names[i]),\n",
    "                n_trials=10000,\n",
    "                min_budget=100,\n",
    "                max_budget=1000,\n",
    "                n_workers=8,\n",
    "\n",
    "            )\n",
    "            \n",
    "\n",
    "            initial_design = MFFacade.get_initial_design(scenario, n_configs=5)\n",
    "            intensifier = intensifier_object(scenario, incumbent_selection=\"highest_budget\")\n",
    "\n",
    "            smac = MFFacade(\n",
    "                scenario,\n",
    "                Tab.fit,\n",
    "                initial_design=initial_design,\n",
    "                intensifier=intensifier,\n",
    "                overwrite=True,\n",
    "            )\n",
    "\n",
    "            print(\"optimizing\")\n",
    "            # print(type(smac), \"|\", smac)\n",
    "            incumbent = smac.optimize()\n",
    "            best_params = incumbent.get_dictionary()\n",
    "            params_dict_Tab[dataset_names[i]] = best_params\n",
    "\n",
    "            print(\"Here 3\")\n",
    "            incumbent_cost = smac.runhistory.get_cost(incumbent)\n",
    "            incumbent_run_id = incumbent.config_id\n",
    "\n",
    "            print(f\"Parameters: {best_params}\")\n",
    "            print(f\"Cost: {incumbent_cost} | Config ID: {incumbent_run_id}\")\n",
    "\n",
    "            # if time.time() - start_time > 60:\n",
    "            #     break\n",
    "\n",
    "            default_cost = smac.validate(Tab.configspace.get_default_configuration())\n",
    "            # print(f\"Default cost ({intensifier.__class__.__name__}): {default_cost}\")\n",
    "            incumbent_cost = smac.validate(incumbent)\n",
    "            # print(f\"Incumbent cost ({intensifier.__class__.__name__}): {incumbent_cost}\")\n",
    "\n",
    "            facades.append(smac)\n",
    "        #     for arrt in dir(smac):\n",
    "        #         if not arrt.startswith(\"_\"):\n",
    "        #             print(arrt, getattr(smac, arrt))\n",
    "\n",
    "        # print(\"facades:\", facades)\n",
    "\n",
    "\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        # with open('smac_results_2h.txt', \"w\") as f:\n",
    "        #     pass\n",
    "        # profiler = LineProfiler()\n",
    "        # profiler.add_function(main)\n",
    "        # profiler.enable()\n",
    "\n",
    "        main()\n",
    "\n",
    "        break\n",
    "\n",
    "        # profiler.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict_Tab = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electricity\n",
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "optimizing\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 100, and max budget 1000.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [5, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [3]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [111.1111111111111, 333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [333.3333333333333, 1000.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [1000.0]\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][smbo.py:319] Finished 0 trials.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][smbo.py:319] Finished 0 trials.\n",
      "[INFO][smbo.py:319] Finished 0 trials.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.61206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.84546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.83813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_auc = 0.83436\n",
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 73 and best_val_0_auc = 0.78852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 67 with best_epoch = 66 and best_val_0_auc = 0.78138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.83638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.65143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.83803\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.83429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_auc = 0.82391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 109 with best_epoch = 99 and best_val_0_auc = 0.82894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 75 with best_epoch = 65 and best_val_0_auc = 0.8187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_auc = 0.85176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 103 with best_epoch = 93 and best_val_0_auc = 0.81333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 70 with best_epoch = 60 and best_val_0_auc = 0.83031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_intensifier.py:515] Added config 58e444 as new incumbent because there are no incumbents yet.\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.59867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_0_auc = 0.84226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.84923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.84576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_auc = 0.85036\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.82548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_intensifier.py:594] Added config d8b89d and rejected config 58e444 as incumbent because it is not better than the incumbents on 1 instances:\n",
      "Stop training because you reached max_epochs = 126 with best_epoch = 124 and best_val_0_auc = 0.81605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.83716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 73 and best_val_0_auc = 0.82933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.84152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.84546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.83813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.84576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.84152\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.84282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_auc = 0.83436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_auc = 0.85176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.84705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_auc = 0.85036\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.8331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_intensifier.py:594] Added config f7eb7e and rejected config d8b89d as incumbent because it is not better than the incumbents on 1 instances:\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_auc = 0.81309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 69 with best_epoch = 61 and best_val_0_auc = 0.82246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.83813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.84152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_auc = 0.8485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_auc = 0.81935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.83321\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.84396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 69 with best_epoch = 61 and best_val_0_auc = 0.82246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.84021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.81874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_auc = 0.8314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.84088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.83723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.82026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.83548\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_auc = 0.85259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_auc = 0.8514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.83725\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.84681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.84259\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_auc = 0.84425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.84021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.84028\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.84088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_auc = 0.8514\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.84681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.84576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.81943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 55 with best_epoch = 48 and best_val_0_auc = 0.83613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_auc = 0.84364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.83157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_auc = 0.84214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.82985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_auc = 0.84516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_auc = 0.84228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.84563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.84112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_auc = 0.84092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_auc = 0.84194\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.84177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 101 with best_epoch = 91 and best_val_0_auc = 0.79715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 51 and best_val_0_auc = 0.85089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_0_auc = 0.8514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_auc = 0.8474\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_auc = 0.83789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 148 with best_epoch = 138 and best_val_0_auc = 0.80285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.83081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 64 with best_epoch = 63 and best_val_0_auc = 0.73089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 51 and best_val_0_auc = 0.85323\n",
      "\n",
      "Early stopping occurred at epoch 88 with best_epoch = 78 and best_val_0_auc = 0.84231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 191 with best_epoch = 181 and best_val_0_auc = 0.76024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 84 with best_epoch = 78 and best_val_0_auc = 0.61597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_auc = 0.69962\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_auc = 0.84214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_auc = 0.84516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 105 with best_epoch = 95 and best_val_0_auc = 0.81681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_auc = 0.85636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.84202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.84177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 91 with best_epoch = 81 and best_val_0_auc = 0.80183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_auc = 0.84524\n",
      "\n",
      "Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_auc = 0.84228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 59 and best_val_0_auc = 0.83643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "[INFO][smbo.py:319] Finished 100 trials.\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_auc = 0.8474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 88 with best_epoch = 78 and best_val_0_auc = 0.84231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_0_auc = 0.76115\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 51 and best_val_0_auc = 0.85323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 55 with best_epoch = 48 and best_val_0_auc = 0.73092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.83519\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.62489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_auc = 0.84516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.52489\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.83063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_auc = 0.83662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_auc = 0.83846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_auc = 0.84851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_auc = 0.84687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_auc = 0.85636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.85032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.84187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 88 with best_epoch = 78 and best_val_0_auc = 0.84231\n",
      "\n",
      "Early stopping occurred at epoch 86 with best_epoch = 76 and best_val_0_auc = 0.71655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.83823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.84344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_0_auc = 0.84108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 52 and best_val_0_auc = 0.84248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.85032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.84187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.82656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_auc = 0.82251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_auc = 0.84687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 94 with best_epoch = 93 and best_val_0_auc = 0.79753\n",
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.82387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.84484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.84062\n",
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_auc = 0.84683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 46 and best_val_0_auc = 0.85769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 77 with best_epoch = 67 and best_val_0_auc = 0.84055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 72 with best_epoch = 65 and best_val_0_auc = 0.76857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.83823\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.84014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.85032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.83901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_auc = 0.83489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.84926\n",
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 45 and best_val_0_auc = 0.84806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 45 and best_val_0_auc = 0.85039\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_0_auc = 0.8443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_auc = 0.83228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.84108\n",
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 45 and best_val_0_auc = 0.84319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.84062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.84484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n",
      "[INFO][smbo.py:319] Finished 150 trials.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 52 and best_val_0_auc = 0.84636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.84014\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.83812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.84485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.83455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.84498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_auc = 0.84655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_auc = 0.84537\n",
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_auc = 0.83791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.8394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.84062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.84926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.84682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.84314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_auc = 0.84625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.83521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.84102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.83455\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.84163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.84498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.83891\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.84682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.85166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.83812\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_auc = 0.85087\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_auc = 0.8409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.84178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_auc = 0.84849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_auc = 0.8521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.84784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 102 with best_epoch = 92 and best_val_0_auc = 0.83506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.83998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 43 and best_val_0_auc = 0.85293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.84498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.84516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.84195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.84729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.84784\n",
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_auc = 0.84686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 73 and best_val_0_auc = 0.85105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_auc = 0.85446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.83998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 77 with best_epoch = 67 and best_val_0_auc = 0.85777\n",
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 43 and best_val_0_auc = 0.84924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 43 and best_val_0_auc = 0.85293\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.84416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_auc = 0.83924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.38475\n",
      "\n",
      "Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_auc = 0.8464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][smbo.py:319] Finished 200 trials.\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_auc = 0.85066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][smbo.py:319] Finished 200 trials.\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.84464\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.84784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_auc = 0.85432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.85196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_auc = 0.84968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.83971\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.84259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.84464\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.84068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_auc = 0.85395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 73 and best_val_0_auc = 0.85105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_auc = 0.85066\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.84658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_auc = 0.85196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_auc = 0.84968\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_auc = 0.84244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.83965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.84104\n",
      "Stop training because you reached max_epochs = 52 with best_epoch = 44 and best_val_0_auc = 0.85245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 48 and best_val_0_auc = 0.84926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_auc = 0.8446\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.8446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_auc = 0.84955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.84769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 88 with best_epoch = 78 and best_val_0_auc = 0.85053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.84171\n",
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.8297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_auc = 0.85023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_auc = 0.84123\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_auc = 0.85395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_auc = 0.85066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 51 and best_val_0_auc = 0.85042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.8422\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.83865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.84769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.83218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 52 and best_val_0_auc = 0.84736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.8297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.82518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_auc = 0.84244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_auc = 0.84955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.83484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 43 and best_val_0_auc = 0.84799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_auc = 0.84139\n",
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_auc = 0.83605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.84266\n",
      "Stop training because you reached max_epochs = 63 with best_epoch = 54 and best_val_0_auc = 0.84998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_auc = 0.84934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 48 and best_val_0_auc = 0.84972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "[INFO][smbo.py:319] Finished 250 trials.\n",
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_auc = 0.84955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.84297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.85218\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.84533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_auc = 0.85306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.85249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.85014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.84344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 132 with best_epoch = 122 and best_val_0_auc = 0.82997\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.83484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 43 and best_val_0_auc = 0.84799\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.85249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 63 with best_epoch = 54 and best_val_0_auc = 0.84998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.82785\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.83664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.83675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_auc = 0.84739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.84971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_auc = 0.85185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 104 with best_epoch = 94 and best_val_0_auc = 0.78358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.8394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_auc = 0.84744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.82387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_0_auc = 0.84838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 43 and best_val_0_auc = 0.84799\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_auc = 0.84412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.8482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.84722\n",
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 52 and best_val_0_auc = 0.85464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.84893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_auc = 0.85205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_auc = 0.85185\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_auc = 0.84744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.84521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.84723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.84593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_auc = 0.84739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.8503\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.84609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.8394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.82723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.84745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.84311\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_auc = 0.84826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.8481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.84022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 48 and best_val_0_auc = 0.84385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_auc = 0.85185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 43 and best_val_0_auc = 0.84523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.84745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][smbo.py:319] Finished 300 trials.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 43 and best_val_0_auc = 0.84803\n",
      "\n",
      "Early stopping occurred at epoch 70 with best_epoch = 60 and best_val_0_auc = 0.85096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_auc = 0.77726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 60 with best_epoch = 50 and best_val_0_auc = 0.84645\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.84723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 48 and best_val_0_auc = 0.84385\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.84441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.85006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.84304\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.82523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_auc = 0.8475\n",
      "Stop training because you reached max_epochs = 86 with best_epoch = 78 and best_val_0_auc = 0.82587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_auc = 0.84559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.8481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 52 and best_val_0_auc = 0.84614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.82723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_0_auc = 0.84982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 134 with best_epoch = 124 and best_val_0_auc = 0.83222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_auc = 0.84846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_auc = 0.85176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 48 and best_val_0_auc = 0.84385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.85061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 46 and best_val_0_auc = 0.80317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.83726\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.4028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_auc = 0.84655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.85006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.79783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_auc = 0.8475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.85061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_intensifier.py:594] Added config d42cca and rejected config f7eb7e as incumbent because it is not better than the incumbents on 1 instances:\n",
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 52 and best_val_0_auc = 0.84614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_auc = 0.84281\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_auc = 0.83923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_0_auc = 0.84608\n",
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 52 and best_val_0_auc = 0.84179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.83599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_auc = 0.85265\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 75 and best_val_0_auc = 0.84864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][smbo.py:327] Configuration budget is exhausted:\n",
      "[INFO][smbo.py:328] --- Remaining wallclock time: -5.900500059127808\n",
      "[INFO][smbo.py:329] --- Remaining cpu time: inf\n",
      "[INFO][smbo.py:330] --- Remaining trials: 9656\n",
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 44 and best_val_0_auc = 0.84946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 45 and best_val_0_auc = 0.84313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 68 with best_epoch = 58 and best_val_0_auc = 0.81099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 46 and best_val_0_auc = 0.84618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.85006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 137 with best_epoch = 128 and best_val_0_auc = 0.80006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyan/miniconda3/envs/NeuroData/lib/python3.9/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here 3\n",
      "Parameters: {'batch_size': 1840, 'lr': 0.0349707715849032, 'max_epochs': 95, 'n_a': 91, 'n_d': 105, 'solver': 'adam'}\n",
      "Cost: 0.20799999999999996 | Config ID: 252\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 98 and best_val_0_auc = 0.73512\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.84721\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for i in range(len(train_x_list)):\n",
    "i = 1\n",
    "train_x = train_x_list[i]\n",
    "train_y = train_y_list[i]\n",
    "print(dataset_names[i])\n",
    "class TabWrapper(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.model = TabNetClassifier(device_name='cuda' if torch.cuda.is_available() else 'cpu', verbose=0)\n",
    "        self.max_epochs = 100\n",
    "        self.batch_size = 1024\n",
    "        self.optimizer_fn = torch.optim.Adam\n",
    "        self.optimizer_params = dict(lr=1e-2)\n",
    "        self.n_d = 8\n",
    "        self.n_a = 8\n",
    "\n",
    "    @property\n",
    "    def configspace(self) -> ConfigurationSpace:\n",
    "        cs = ConfigurationSpace()\n",
    "        n_d = Integer(\"n_d\", (4, 128), default=8)\n",
    "        n_a = Integer(\"n_a\", (4, 128), default=8)\n",
    "        max_epochs = Integer(\"max_epochs\", (50, 300), default=100)\n",
    "        batch_size = Integer(\"batch_size\", (64, 2048), default=1024)\n",
    "        solver = Categorical(\"solver\", [\"sgd\", \"adam\"])\n",
    "        # optimizer_fn = Categorical(\"optimizer_fn\", [torch.optim.Adam, torch.optim.SGD], default=torch.optim.Adam)\n",
    "        lr = Float(\"lr\", (0.001, 0.1), default=1e-2)\n",
    "        cs.add_hyperparameters([n_d, n_a, max_epochs, batch_size, solver, lr])\n",
    "        return cs\n",
    "\n",
    "    def fit(self, config: Configuration, seed: int = 0, budget: int = 250) -> float:\n",
    "        self.lr = config.get(\"lr\")\n",
    "        self.optimizer_params.update({\"lr\": self.lr})\n",
    "        self.n_d = config.get(\"n_d\")\n",
    "        self.n_a = config.get(\"n_a\")\n",
    "        self.max_epochs = config.get(\"max_epochs\")\n",
    "        self.batch_size = config.get(\"batch_size\")\n",
    "        solver_name = config.get(\"solver\")\n",
    "        if solver_name == \"adam\":\n",
    "            self.optimizer_fn = torch.optim.Adam\n",
    "        else:\n",
    "            self.optimizer_fn = torch.optim.SGD\n",
    "        self.model = TabNetClassifier(n_d=self.n_d, n_a=self.n_a, optimizer_params=self.optimizer_params, optimizer_fn=self.optimizer_fn, verbose=0)\n",
    "        X = train_x\n",
    "        y = train_y\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=317)\n",
    "        self.model.fit(X_train, y_train, eval_set=[(X_val, y_val)], max_epochs=self.max_epochs, patience=10, batch_size=self.batch_size)\n",
    "        preds = self.model.predict(X_val)\n",
    "        score = accuracy_score(y_val, preds)\n",
    "        return 1 - score\n",
    "        # return None\n",
    "\n",
    "\n",
    "@timeout(4000)\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    Tab = TabWrapper()\n",
    "\n",
    "    facades: list[AbstractFacade] = []\n",
    "    for intensifier_object in [Hyperband]:\n",
    "\n",
    "        scenario = Scenario(\n",
    "            Tab.configspace,\n",
    "            walltime_limit=3600,\n",
    "            output_directory=Path(\"smac_hyperband_output_budget_1hr_Tab_337/\" + dataset_names[i]),\n",
    "            n_trials=10000,\n",
    "            min_budget=100,\n",
    "            max_budget=1000,\n",
    "            n_workers=8,\n",
    "\n",
    "        )\n",
    "        \n",
    "\n",
    "        initial_design = MFFacade.get_initial_design(scenario, n_configs=5)\n",
    "        intensifier = intensifier_object(scenario, incumbent_selection=\"highest_budget\")\n",
    "\n",
    "        smac = MFFacade(\n",
    "            scenario,\n",
    "            Tab.fit,\n",
    "            initial_design=initial_design,\n",
    "            intensifier=intensifier,\n",
    "            overwrite=True,\n",
    "        )\n",
    "\n",
    "        print(\"optimizing\")\n",
    "        # print(type(smac), \"|\", smac)\n",
    "        incumbent = smac.optimize()\n",
    "        best_params = incumbent.get_dictionary()\n",
    "        params_dict_Tab[dataset_names[i]] = best_params\n",
    "\n",
    "        print(\"Here 3\")\n",
    "        incumbent_cost = smac.runhistory.get_cost(incumbent)\n",
    "        incumbent_run_id = incumbent.config_id\n",
    "\n",
    "        print(f\"Parameters: {best_params}\")\n",
    "        print(f\"Cost: {incumbent_cost} | Config ID: {incumbent_run_id}\")\n",
    "\n",
    "        # if time.time() - start_time > 60:\n",
    "        #     break\n",
    "\n",
    "        default_cost = smac.validate(Tab.configspace.get_default_configuration())\n",
    "        # print(f\"Default cost ({intensifier.__class__.__name__}): {default_cost}\")\n",
    "        incumbent_cost = smac.validate(incumbent)\n",
    "        # print(f\"Incumbent cost ({intensifier.__class__.__name__}): {incumbent_cost}\")\n",
    "\n",
    "        facades.append(smac)\n",
    "    #     for arrt in dir(smac):\n",
    "    #         if not arrt.startswith(\"_\"):\n",
    "    #             print(arrt, getattr(smac, arrt))\n",
    "\n",
    "    # print(\"facades:\", facades)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # with open('smac_results_2h.txt', \"w\") as f:\n",
    "    #     pass\n",
    "    # profiler = LineProfiler()\n",
    "    # profiler.add_function(main)\n",
    "    # profiler.enable()\n",
    "\n",
    "    main()\n",
    "    # break\n",
    "\n",
    "    # profiler.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of runhistory_data_CNN: 64\n",
      "CNN min 1:\n",
      "Config ID: 37, Cost: 0.22150000000000003, Parameters: {'batch_size': 153, 'lr': 0.04598482365380299, 'max_epochs': 65, 'n_a': 113, 'n_d': 62, 'solver': 'adam'}\n",
      "\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "name = \"road-safety\"\n",
    "runhistory_path = \"smac_hyperband_output_budget_30mins_Tab_334/road-safety/cf8dee3b8e13ab59fd3239374ffb1556/0/runhistory.json\"\n",
    "\n",
    "with open(runhistory_path, \"r\") as file:\n",
    "    runhistory_data_CNN = json.load(file)\n",
    "\n",
    "print(\"Length of runhistory_data_CNN:\", len(runhistory_data_CNN[\"data\"]))\n",
    "\n",
    "configs_costs_CNN = []\n",
    "for entry in runhistory_data_CNN[\"data\"]:\n",
    "    # print(entry)\n",
    "    config_id = entry[0]  \n",
    "    cost = entry[4]  \n",
    "    configs_costs_CNN.append((entry[0], entry[4]))\n",
    "    configs_costs_CNN = list(set(configs_costs_CNN))\n",
    "\n",
    "    # print(f\"Config ID: {config_id}, Cost: {cost}\")\n",
    "    # if config_id == 44:# or config_id == 21:\n",
    "    #     params_CNN = runhistory_data_CNN[\"configs\"][str(config_id)]\n",
    "    #     # print(entry)\n",
    "    #     print(f\"CNN config ID: {config_id}, Cost: {cost}, Parameters: {params_CNN}\\n\")\n",
    "\n",
    "\n",
    "# min_cost_config_CNN = []\n",
    "# min_cost_config_CNN = sorted(configs_costs_CNN, key=lambda x: x[1])[:3]\n",
    "# print(\"CNN min 3:\")\n",
    "# for config_id, cost in min_cost_config_CNN:\n",
    "    \n",
    "#     params = runhistory_data_CNN[\"configs\"][str(config_id)]\n",
    "#     print(f\"Config ID: {config_id}, Cost: {cost}, Parameters: {params}\\n\")\n",
    "min_cost_config_CNN = sorted(configs_costs_CNN, key=lambda x: x[1])[0]\n",
    "print(\"CNN min 1:\")\n",
    "config_id, cost = min_cost_config_CNN\n",
    "params = runhistory_data_CNN[\"configs\"][str(config_id)]\n",
    "print(f\"Config ID: {config_id}, Cost: {cost}, Parameters: {params}\\n\")\n",
    "params_dict_Tab[name] = params\n",
    "file.close()\n",
    "print(len(params_dict_Tab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['electricity', 'eye_movements', 'covertype', 'albert', 'default-of-credit-card-clients', 'road-safety', 'compas-two-years']\n",
      "7\n",
      "albert : {'batch_size': 352, 'lr': 0.07019238667793253, 'max_epochs': 219, 'n_a': 106, 'n_d': 79, 'solver': 'adam'}\n",
      "covertype : {'batch_size': 266, 'lr': 0.07478404831565831, 'max_epochs': 234, 'n_a': 120, 'n_d': 101, 'solver': 'adam'}\n",
      "compas-two-years : {'batch_size': 1153, 'lr': 0.06494351719359896, 'max_epochs': 248, 'n_a': 14, 'n_d': 126, 'solver': 'adam'}\n",
      "default-of-credit-card-clients : {'batch_size': 431, 'lr': 0.004253519924914082, 'max_epochs': 191, 'n_a': 89, 'n_d': 126, 'solver': 'adam'}\n",
      "electricity : {'batch_size': 1522, 'lr': 0.02494659672017355, 'max_epochs': 87, 'n_a': 111, 'n_d': 26, 'solver': 'adam'}\n",
      "eye_movements : {'batch_size': 854, 'lr': 0.04770160470431317, 'max_epochs': 68, 'n_a': 96, 'n_d': 13, 'solver': 'adam'}\n",
      "road-safety : {'batch_size': 153, 'lr': 0.04598482365380299, 'max_epochs': 65, 'n_a': 113, 'n_d': 62, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset_names)\n",
    "# print(type(params_dict_Tab))\n",
    "print(len(params_dict_Tab))\n",
    "\n",
    "for dataset_name, params in params_dict_Tab.items():\n",
    "    print(dataset_name, \":\", params)\n",
    "\n",
    "with open('SmacResults/334/Tab_params_1hr.json', 'w') as f:\n",
    "    json.dump(params_dict_Tab, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter Kernel",
   "language": "python",
   "name": "neurodata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
